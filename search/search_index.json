{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"The Tabbed Guide"},{"location":"#introduction","title":"Introduction","text":"<ul> <li>Tabbed is a fast, iterative &amp; selective reader of irregularly structured text files.</li> </ul> <ul> <li> </li> <li> </li> <li> </li> <li> </li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#reference","title":"Reference","text":""},{"location":"#about","title":"About","text":""},{"location":"#key-features","title":"Key Features","text":"<ul> <li>automatic type inference</li> <li>metadata, header and data section detection</li> <li>sophisticated value based row filtering</li> <li>high-speed iterative reading of large files</li> <li>partial file reading</li> <li>flexible handling of missing data</li> </ul>"},{"location":"about/","title":"About","text":""},{"location":"about/#purpose","title":"Purpose","text":"<p>Tabbed was developed out of necessity. We work with text files from many different software vendors that create their own idiosyncratic CSV files that we need to read for machine and deep-learning projects. These files include different kinds of metadata, unusual headers, and different representations of \"missing\" values.  We also found no way to conditionally read rows from files that are very large.  These considerations motivated us to create tabbed. If you find Tabbed useful in your work, please cite tabbed's paper.</p>"},{"location":"about/#acknowledgements","title":"Acknowledgements We are grateful for the support of the Ting Tsung and Wei Fong Chao Foundation and the Jan and Dan Duncan Neurological Research Institute at Texas Children's that generously supports Tabbed.","text":"<p>License</p> <p>Tabbed is released under the BSD-3 Clause License.</p> <p>BSD 3-Clause License</p> <p>Copyright (c) 2025, Tabbed Developers Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#introduction","title":"Introduction","text":"<p>This guide walks you through reading a text file that contains metadata, a header row and mixed data types with <code>Tabbed</code>.</p> <ul> <li> Sample File</li> <li> Tabbed Wish List</li> <li> The Tabbed Reader</li> <li> Data Filtering</li> <li> Reading</li> <li> When Something Goes Wrong</li> </ul> Imports<pre><code>import os\nimport tempfile\nimport random\nfrom datetime import datetime, timedelta\n\nfrom tabbed import samples\nfrom tabbed.reading import Reader\n</code></pre>"},{"location":"getting_started/#sample-file","title":"Sample File","text":"<p>Tabbed comes preloaded with a sample text file called annotations.txt. Below we open this file to see what it looks like and develop a list of operations we would like Tabbed to handle automatically for us.</p> Preview Sample Data<pre><code>fp = samples.paths.annotations\nwith open(fp, 'r') as infile:\n    for line in infile:\n        print(line, end='')\n</code></pre> View Sample Data <p>Experiment ID\u2003Experiment Animal ID\u2003Animal Researcher\u2003Test Directory path\u2003  </p> <p>Number\u2003Start Time\u2003End Time\u2003Time From Start\u2003Channel\u2003Annotation 0\u200302/09/22 09:17:38.948\u200302/09/22 09:17:38.948\u20030.0000\u2003ALL\u2003Started Recording 1\u200302/09/22 09:37:00.000\u200302/09/22 09:37:00.000\u20031161.0520\u2003ALL\u2003start 2\u200302/09/22 09:37:00.000\u200302/09/22 09:37:08.784\u20031161.0520\u2003ALL\u2003exploring 3\u200302/09/22 09:37:08.784\u200302/09/22 09:37:13.897\u20031169.8360\u2003ALL\u2003grooming 4\u200302/09/22 09:37:13.897\u200302/09/22 09:38:01.262\u20031174.9490\u2003ALL\u2003exploring 5\u200302/09/22 09:38:01.262\u200302/09/22 09:38:07.909\u20031222.3140\u2003ALL\u2003grooming 6\u200302/09/22 09:38:07.909\u200302/09/22 09:38:20.258\u20031228.9610\u2003ALL\u2003exploring 7\u200302/09/22 09:38:20.258\u200302/09/22 09:38:25.435\u20031241.3100\u2003ALL\u2003grooming 8\u200302/09/22 09:38:25.435\u200302/09/22 09:40:07.055\u20031246.4870\u2003ALL\u2003exploring 9\u200302/09/22 09:40:07.055\u200302/09/22 09:40:22.334\u20031348.1070\u2003ALL\u2003grooming 10\u200302/09/22 09:40:22.334\u200302/09/22 09:41:36.664\u20031363.3860\u2003ALL\u2003exploring 11\u200302/09/22 09:41:36.664\u200302/09/22 09:41:46.326\u20031437.7160\u2003ALL\u2003grooming 12\u200302/09/22 09:41:46.326\u200302/09/22 09:44:16.857\u20031447.3780\u2003ALL\u2003exploring 13\u200302/09/22 09:44:16.857\u200302/09/22 09:44:58.225\u20031597.9090\u2003ALL\u2003grooming 14\u200302/09/22 09:44:58.225\u200302/09/22 09:45:35.800\u20031639.2770\u2003ALL\u2003exploring 15\u200302/09/22 09:45:35.800\u200302/09/22 09:45:40.506\u20031676.8520\u2003ALL\u2003grooming 16\u200302/09/22 09:45:40.506\u200302/09/22 09:47:03.165\u20031681.5580\u2003ALL\u2003exploring 17\u200302/09/22 09:47:03.165\u200302/09/22 09:47:16.448\u20031764.2170\u2003ALL\u2003grooming 18\u200302/09/22 09:47:16.448\u200302/09/22 09:47:55.227\u20031777.5000\u2003ALL\u2003exploring 19\u200302/09/22 09:47:55.227\u200302/09/22 09:48:05.044\u20031816.2790\u2003ALL\u2003grooming 20\u200302/09/22 09:48:05.044\u200302/09/22 09:51:40.919\u20031826.0960\u2003ALL\u2003exploring 21\u200302/09/22 09:51:40.919\u200302/09/22 09:51:47.331\u20032041.9710\u2003ALL\u2003grooming 22\u200302/09/22 09:51:47.331\u200302/09/22 09:52:20.626\u20032048.3830\u2003ALL\u2003exploring 23\u200302/09/22 09:52:20.626\u200302/09/22 09:52:29.406\u20032081.6780\u2003ALL\u2003grooming 24\u200302/09/22 09:52:29.406\u200302/09/22 09:53:07.268\u20032090.4580\u2003ALL\u2003exploring 25\u200302/09/22 09:53:07.268\u200302/09/22 09:53:21.147\u20032128.3200\u2003ALL\u2003grooming 26\u200302/09/22 09:53:21.147\u200302/09/22 09:54:19.752\u20032142.1990\u2003ALL\u2003exploring 27\u200302/09/22 09:54:19.752\u200302/09/22 09:54:38.782\u20032200.8040\u2003ALL\u2003grooming 28\u200302/09/22 09:54:38.782\u200302/09/22 09:56:30.491\u20032219.8340\u2003ALL\u2003exploring 29\u200302/09/22 09:56:30.491\u200302/09/22 09:56:40.306\u20032331.5430\u2003ALL\u2003grooming 30\u200302/09/22 09:56:40.306\u200302/09/22 09:57:11.920\u20032341.3580\u2003ALL\u2003exploring 31\u200302/09/22 09:57:11.920\u200302/09/22 09:57:18.783\u20032372.9720\u2003ALL\u2003grooming 32\u200302/09/22 09:57:18.783\u200302/09/22 10:00:02.036\u20032379.8350\u2003ALL\u2003exploring 33\u200302/09/22 10:00:02.036\u200302/09/22 10:00:08.325\u20032543.0880\u2003ALL\u2003resting 34\u200302/09/22 10:00:08.325\u200302/09/22 10:01:57.278\u20032549.3770\u2003ALL\u2003exploring 35\u200302/09/22 10:01:57.278\u200302/09/22 10:02:17.993\u20032658.3300\u2003ALL\u2003grooming 36\u200302/09/22 10:02:17.993\u200302/09/22 10:03:04.118\u20032679.0450\u2003ALL\u2003exploring 37\u200302/09/22 10:03:04.118\u200302/09/22 10:03:04.118\u20032725.1700\u2003ALL\u2003stop 38\u200302/09/22 10:17:30.082\u200302/09/22 10:17:30.082\u20033591.1340\u2003ALL\u2003Stopped Recording  </p>"},{"location":"getting_started/#tabbed-wish-list","title":"Tabbed Wish List","text":"<p>To read files like this, we desire Tabbed to support the following:</p> Header DetectionType InferenceData FilteringPartial &amp; Iterative ReadingFlexibility <p> Header Detection</p> <p>This sample file contains a metadata section prior to the header on line 7. Metadata can be unstructured like a paragraph or structured into columns separated by a delimiter. We want <code>Tabbed</code> to automatically detect the Metadata section and Header line of any file.</p> <p> Type Inference</p> <p>The string cells in the sample file are encoding 4 different data types; integers, datetimes, floats and strings. We want <code>Tabbed</code> to perform  Type inference.</p> <p> Data Filtering</p> <p>We want <code>Tabbed</code> to support simple value based row and column filtering. For example, in this file we might want only rows at which the <code>Start Time</code> column is less than <code>datetime(2022, 2, 9, 9, 37, 13)</code> or where the <code>Annotation</code> column has a string value of <code>'exploring'</code> or both conditions.</p> <p> Partial &amp; Iterative Reading</p> <p>Text files can be large. <code>Tabbed</code> should support partial and iterative reading.</p> <p> Flexibility</p> <p>Tabbed should be flexible. It should be able to <code>start</code> reading at any file position, <code>skip</code> reading of 'bad' rows, and allow users to choose how much  memory to consume during iterative reading of large files. </p>"},{"location":"getting_started/#the-tabbed-reader","title":"The Tabbed Reader","text":"<p>Tabbed's <code>Reader</code> reads rows of an infile to dictionaries just like Python's built-in <code>csv.DictReader</code>. However, Tabbed's <code>Reader</code> embeds a sophisticated file <code>Sniffer</code> that can detect metadata, header &amp; data sections of a file automatically (for details see Sniffer). The detected metadata, header and datatypes are available to the reader as properties. In this section, we will build a reader and see how to access the file's dialect, metadata, header, and inferred datatypes.</p> Building a Reader<pre><code>fp = samples.paths.annotations\ninfile = open(fp, 'r')\n# like Python's csv.DictReader, we pass an open file instance\nreader = Reader(infile)\n</code></pre> Accessing Dialect<pre><code>fp = samples.paths.annotations\ninfile = open(fp, 'r')\n# like Python's csv.DictReader, we pass an open file instance\nreader = Reader(infile)\nprint(reader.sniffer.dialect)\n</code></pre> <p>Dialect</p> <p>SimpleDialect('\\t', '\"', None)</p> <p>The output dialect is a SimpleDialect instance of the  clevercsv package.</p> Metadata &amp; Header Detection<pre><code># the reader's header and metadata properties call the sniffer\nprint(reader.header)\nprint('---')\nprint(reader.metadata())\n</code></pre> <p>Metadata and Header Detection</p> <p>Header(line=6, names=['Number', 'Start_Time', 'End_Time', 'Time_From_Start', 'Channel', 'Annotation'], string='Number\\tStart Time\\tEnd Time\\tTime From Start\\tChannel\\tAnnotation')</p> <p>MetaData(lines=(0, 6), string='Experiment ID\\tExperiment\\nAnimal ID\\tAnimal\\nResearcher\\tTest\\nDirectory path\\t\\n\\n')</p> <p>The Header was detected on line 6 and has 6 column names. The metadata string spans from line 0 upto line 6. The embedded <code>Sniffer</code> instance samples the file when the reader is created.</p> Type Inference<pre><code># request the sniffed types by polling the last 10 rows of the sniffed sample\n# consistent is a `bool` indicating if types are consistent across sample rows\ntypes, consistent = reader.sniffer.types(poll=10)\nprint(types)\n</code></pre> <p>Type Inference</p> <p><code>[&lt;class 'int'&gt;, &lt;class 'datetime.datetime'&gt;, &lt;class 'datetime.datetime'&gt;, &lt;class 'float'&gt;, &lt;class 'str'&gt;, &lt;class 'str'&gt;]</code></p> <p>Our deep testing on randomly generated text files indicates that Tabbed's <code>Reader</code> will detect dialect, metadata, header, and types correctly in most cases. Should you encounter a problem, you can change the sample the Sniffer uses to measure these properties. The <code>Sniffer</code>'s <code>start</code>,<code>amount</code>, &amp; <code>skips</code> alter the sniffing sample. You can also change what sample rows are used for type polling via the <code>poll</code> and <code>exclude</code> arguments of the Reader initializer. All these arguments can help in the auto-detection of the header and metadata sections of a text file.  For help understanding these parameters type <code>help(reader.sniffer)</code> or see Sniffer. Below, we show the sniffer and it's default parameters used in this example.</p> Default Sniffer<pre><code>#print the current sniffer used by the reader\nprint(reader.sniffer)\n</code></pre> <pre><code>Sniffer\n--- Attributes ---\ninfile: &lt;_io.TextIOWr...oding='UTF-8'&gt;\ndecimal: '.'\n--- Properties ---\namount: 100\ndialect: SimpleDialect('\\t', '\"', None)\nlines: [0, 1, 2, 3, 4, 5, ...]\nrows: [['Experiment ID', 'Experiment'], ['Animal ID', 'Animal'], ['Researcher', 'Test'], ['Directory path'], [''], [''], ...]\nsample: 'Experiment I...d Recording\\n'\nskips: []\nstart: 0\n--- Methods ---\ndatetime_formats\nheader\nmetadata\nsniff\ntypes\nType help(Sniffer) for full documentation\n</code></pre> Default Reader<pre><code>#print the poll and exlude default arguments.\nprint(reader.poll, reader.exclude)\n</code></pre> <pre><code>20 ['', ' ', '-', 'nan', 'NaN', 'NAN']\n</code></pre>"},{"location":"getting_started/#data-filtering","title":"Data Filtering","text":"<p><code>Tabbed</code> provides a powerful mechanism for value-based filtering of rows and columns. These filters are called Tabs in <code>Tabbed</code> and support equality, membership, rich comparison, regular expression, and custom filtering of data. The <code>reader.tab</code> method provides a simple way to construct <code>Tabs</code> with keyword arguments.</p>"},{"location":"getting_started/#equality-tabbing","title":"Equality Tabbing","text":"Equality Tabbing Example<pre><code>reader.tab(Annotation='exploring', columns=['Number', 'Annotation'])\nfor row in chain.from_iterable(reader.read()):\n    print(row)\n</code></pre> <pre><code>{'Number': 2, 'Annotation': 'exploring'}\n{'Number': 4, 'Annotation': 'exploring'}\n{'Number': 6, 'Annotation': 'exploring'}\n{'Number': 8, 'Annotation': 'exploring'}\n{'Number': 10, 'Annotation': 'exploring'}\n{'Number': 12, 'Annotation': 'exploring'}\n{'Number': 14, 'Annotation': 'exploring'}\n{'Number': 16, 'Annotation': 'exploring'}\n{'Number': 18, 'Annotation': 'exploring'}\n{'Number': 20, 'Annotation': 'exploring'}\n{'Number': 22, 'Annotation': 'exploring'}\n{'Number': 24, 'Annotation': 'exploring'}\n{'Number': 26, 'Annotation': 'exploring'}\n{'Number': 28, 'Annotation': 'exploring'}\n{'Number': 30, 'Annotation': 'exploring'}\n{'Number': 32, 'Annotation': 'exploring'}\n{'Number': 34, 'Annotation': 'exploring'}\n{'Number': 36, 'Annotation': 'exploring'}\n</code></pre> <p>For now ignore the <code>chain.from_iterable(reader.read())</code> and focus on the highlihted line (1) where we tab the rows in the Annotation column whose value equals exploring and request the reader to only read the Number and Annotation columns. Notice the output row dictionaries consist of rows that match this Tabbing. For more details on <code>Equality</code> tabbing please see the  Equality Tab </p>"},{"location":"getting_started/#membership-tabbing","title":"Membership Tabbing","text":"Membership Tabbing Example<pre><code>reader.tab(Annotation=['exploring', 'resting'], columns=[0, 5])\nfor row in chain.from_iterable(reader.read()):\n    print(row)\n</code></pre> <pre><code>{'Number': 2, 'Annotation': 'exploring'}\n{'Number': 4, 'Annotation': 'exploring'}\n{'Number': 6, 'Annotation': 'exploring'}\n{'Number': 8, 'Annotation': 'exploring'}\n{'Number': 10, 'Annotation': 'exploring'}\n{'Number': 12, 'Annotation': 'exploring'}\n{'Number': 14, 'Annotation': 'exploring'}\n{'Number': 16, 'Annotation': 'exploring'}\n{'Number': 18, 'Annotation': 'exploring'}\n{'Number': 20, 'Annotation': 'exploring'}\n{'Number': 22, 'Annotation': 'exploring'}\n{'Number': 24, 'Annotation': 'exploring'}\n{'Number': 26, 'Annotation': 'exploring'}\n{'Number': 28, 'Annotation': 'exploring'}\n{'Number': 30, 'Annotation': 'exploring'}\n{'Number': 32, 'Annotation': 'exploring'}\n{'Number': 33, 'Annotation': 'resting'}\n{'Number': 34, 'Annotation': 'exploring'}\n{'Number': 36, 'Annotation': 'exploring'}\n</code></pre> <p>Focus on the highlihted line (1) where we tab the rows in the Annotation column whose value is in <code>['exploring', 'resting']</code> and request the reader to only read the Number and Annotation columns using column indexing. Notice the output row dictionaries consist of rows that match this Tabbing. For more details on <code>Membership</code> tabbing please see the Membership Tab </p>"},{"location":"getting_started/#comparison-tabbing","title":"Comparison Tabbing","text":"Rich Comparison Tabbing Example<pre><code># get all the annotations between 9:38:00 and 9:42:00\nreader.tab(Start_Time='&gt; 9/2/2022 9:38:00 and &lt; 9/2/2022 9:42:00', columns=[0, 1])\nfor row in chain.from_iterable(reader.read()):\n    print(row)\n</code></pre> <pre><code>{'Number': 5, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 38, 1, 262000)}\n{'Number': 6, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 38, 7, 909000)}\n{'Number': 7, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 38, 20, 258000)}\n{'Number': 8, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 38, 25, 435000)}\n{'Number': 9, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 40, 7, 55000)}\n{'Number': 10, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 40, 22, 334000)}\n{'Number': 11, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 41, 36, 664000)}\n{'Number': 12, 'Start_Time': datetime.datetime(2022, 2, 9, 9, 41, 46, 326000)}\n</code></pre> <p>Again, focus on the highlihted line (2) where we tab the rows in the Start_Time column whose value is between <code>'9:38:00'</code> and <code>'9:42:00'</code> and request the reader to only read the Number and Start_Time columns using column indexing.  Notice the output row dictionaries consist of rows that match this Tabbing. For more details on <code>Comparison</code> tabbing please see the Comparison Tab </p>"},{"location":"getting_started/#regular-expression-tabbing","title":"Regular Expression Tabbing","text":"Regular Expression Tabbing Example<pre><code>import re\n# get all the annotations that contain start with 'g' or 'r'\nreader.tab(Annotation=re.compile(r'^[g|r]'), columns=[0, 1])\nfor row in chain.from_iterable(reader.read()):\n    print(row)\n</code></pre> <pre><code>{'Number': 3, 'Annotation': 'grooming'}\n{'Number': 5, 'Annotation': 'grooming'}\n{'Number': 7, 'Annotation': 'grooming'}\n{'Number': 9, 'Annotation': 'grooming'}\n{'Number': 11, 'Annotation': 'grooming'}\n{'Number': 13, 'Annotation': 'grooming'}\n{'Number': 15, 'Annotation': 'grooming'}\n{'Number': 17, 'Annotation': 'grooming'}\n{'Number': 19, 'Annotation': 'grooming'}\n{'Number': 21, 'Annotation': 'grooming'}\n{'Number': 23, 'Annotation': 'grooming'}\n{'Number': 25, 'Annotation': 'grooming'}\n{'Number': 27, 'Annotation': 'grooming'}\n{'Number': 29, 'Annotation': 'grooming'}\n{'Number': 31, 'Annotation': 'grooming'}\n{'Number': 33, 'Annotation': 'resting'}\n{'Number': 35, 'Annotation': 'grooming'}\n</code></pre> <p>Focus on the highlihted line (3) where we tab the rows in the Start_Time column whose value is between <code>'9:38:00'</code> and <code>'9:42:00'</code> and request the reader to only read the Number and Start_Time columns using column indexing.  Notice the output row dictionaries consist of rows that match this Tabbing. For more details on <code>Regex</code> tabbing please see the: Regex Tab </p>"},{"location":"getting_started/#custom-tabbing","title":"Custom Tabbing","text":"<p>Tabbed also supports construction of <code>Calling</code> Tabs that allow you to provide your own custom logic for row filtering. For details see the Calling Tab in the reference manual.</p>"},{"location":"getting_started/#reading","title":"Reading","text":"<p>The <code>Reader.read</code> method returns an iterator of lists. Each yielded list contains row dictionaries from the data section. The values in each <code>dict</code> are the type casted and tab filtered rows. The <code>chunksize</code> parameter of the <code>read</code> method determines how many row dictionaries to yield per iteration. Let's take a look at the <code>read</code> method with our sample file.  </p> Return Type<pre><code># for ease of reading just get the Number &amp; Annotation columns\nreader.tab(columns=['Number', 'Annotation'])\n# calling read creates an iterator\ngen = reader.read(chunksize=5)\nprint(type(gen))\n</code></pre> <p>Return Type</p> <p><code>&lt;class 'generator'&gt;</code></p> Chunksize<pre><code>for idx, chunk in enumerate(reader.read(chunksize=2)):\n    print(f'chunk {idx}: {chunk}')\n</code></pre> chunksize <p>chunk 0: <code>[{'Number': 0, 'Annotation': 'Started Recording'}, {'Number': 1, 'Annotation': 'start'}]</code>chunk 1: <code>[{'Number': 2, 'Annotation': 'exploring'}, {'Number': 3, 'Annotation': 'grooming'}]</code>chunk 2: <code>[{'Number': 4, 'Annotation': 'exploring'}, {'Number': 5, 'Annotation': 'grooming'}]</code>chunk 3: <code>[{'Number': 6, 'Annotation': 'exploring'}, {'Number': 7, 'Annotation': 'grooming'}]</code>chunk 4: <code>[{'Number': 8, 'Annotation': 'exploring'}, {'Number': 9, 'Annotation': 'grooming'}]</code>chunk 5: <code>[{'Number': 10, 'Annotation': 'exploring'}, {'Number': 11, 'Annotation': 'grooming'}]</code>chunk 6: <code>[{'Number': 12, 'Annotation': 'exploring'}, {'Number': 13, 'Annotation': 'grooming'}]</code>chunk 7: <code>[{'Number': 14, 'Annotation': 'exploring'}, {'Number': 15, 'Annotation': 'grooming'}]</code>chunk 8: <code>[{'Number': 16, 'Annotation': 'exploring'}, {'Number': 17, 'Annotation': 'grooming'}]</code>chunk 9: <code>[{'Number': 18, 'Annotation': 'exploring'}, {'Number': 19, 'Annotation': 'grooming'}]</code>chunk 10: <code>[{'Number': 20, 'Annotation': 'exploring'}, {'Number': 21, 'Annotation': 'grooming'}]</code>chunk 11: <code>[{'Number': 22, 'Annotation': 'exploring'}, {'Number': 23, 'Annotation': 'grooming'}]</code>chunk 12: <code>[{'Number': 24, 'Annotation': 'exploring'}, {'Number': 25, 'Annotation': 'grooming'}]</code>chunk 13: <code>[{'Number': 26, 'Annotation': 'exploring'}, {'Number': 27, 'Annotation': 'grooming'}]</code>chunk 14: <code>[{'Number': 28, 'Annotation': 'exploring'}, {'Number': 29, 'Annotation': 'grooming'}]</code>chunk 15: <code>[{'Number': 30, 'Annotation': 'exploring'}, {'Number': 31, 'Annotation': 'grooming'}]</code>chunk 16: <code>[{'Number': 32, 'Annotation': 'exploring'}, {'Number': 33, 'Annotation': 'resting'}]</code>chunk 17: <code>[{'Number': 34, 'Annotation': 'exploring'}, {'Number': 35, 'Annotation': 'grooming'}]</code>chunk 18: <code>[{'Number': 36, 'Annotation': 'exploring'}, {'Number': 37, 'Annotation': 'stop'}]</code>chunk 19: <code>[{'Number': 38, 'Annotation': 'Stopped Recording'}]</code></p> <p>Each <code>yield</code> of the read iterator gave us 2 rows from the data section. You can set the <code>chunksize</code> to any <code>int</code> value. The default is 200,000 rows per yield. Read has several parameters for controlling what rows will be yielded. These include;  <code>start</code>, <code>skips</code> and <code>indices</code>. Details on these parameters can be found using <code>help(Reader.read)</code> or read's documentation. </p> <p>The <code>read</code> method always returns an iterator but for small files you may want to read the file in completely. This is simple using python's <code>itertools</code> module. Below is a recipe for converting read's iterator to an in-memory list. </p> As in-memory list<pre><code>from itertools import chain\ndata = list(chain.from_iterable(reader.read(chunksize=2)))\nprint(*data, sep='\\n')\n</code></pre> Reading to an in-memory list <p><code>{'Number': 0, 'Annotation': 'Started Recording'}</code><code>{'Number': 1, 'Annotation': 'start'}</code><code>{'Number': 2, 'Annotation': 'exploring'}</code><code>{'Number': 3, 'Annotation': 'grooming'}</code><code>{'Number': 4, 'Annotation': 'exploring'}</code><code>{'Number': 5, 'Annotation': 'grooming'}</code><code>{'Number': 6, 'Annotation': 'exploring'}</code><code>{'Number': 7, 'Annotation': 'grooming'}</code><code>{'Number': 8, 'Annotation': 'exploring'}</code><code>{'Number': 9, 'Annotation': 'grooming'}</code><code>{'Number': 10, 'Annotation': 'exploring'}</code><code>{'Number': 11, 'Annotation': 'grooming'}</code><code>{'Number': 12, 'Annotation': 'exploring'}</code><code>{'Number': 13, 'Annotation': 'grooming'}</code><code>{'Number': 14, 'Annotation': 'exploring'}</code><code>{'Number': 15, 'Annotation': 'grooming'}</code><code>{'Number': 16, 'Annotation': 'exploring'}</code><code>{'Number': 17, 'Annotation': 'grooming'}</code><code>{'Number': 18, 'Annotation': 'exploring'}</code><code>{'Number': 19, 'Annotation': 'grooming'}</code><code>{'Number': 20, 'Annotation': 'exploring'}</code><code>{'Number': 21, 'Annotation': 'grooming'}</code><code>{'Number': 22, 'Annotation': 'exploring'}</code><code>{'Number': 23, 'Annotation': 'grooming'}</code><code>{'Number': 24, 'Annotation': 'exploring'}</code><code>{'Number': 25, 'Annotation': 'grooming'}</code><code>{'Number': 26, 'Annotation': 'exploring'}</code><code>{'Number': 27, 'Annotation': 'grooming'}</code><code>{'Number': 28, 'Annotation': 'exploring'}</code><code>{'Number': 29, 'Annotation': 'grooming'}</code><code>{'Number': 30, 'Annotation': 'exploring'}</code><code>{'Number': 31, 'Annotation': 'grooming'}</code><code>{'Number': 32, 'Annotation': 'exploring'}</code><code>{'Number': 33, 'Annotation': 'resting'}</code><code>{'Number': 34, 'Annotation': 'exploring'}</code><code>{'Number': 35, 'Annotation': 'grooming'}</code><code>{'Number': 36, 'Annotation': 'exploring'}</code><code>{'Number': 37, 'Annotation': 'stop'}</code><code>{'Number': 38, 'Annotation': 'Stopped Recording'}</code></p>"},{"location":"getting_started/#when-something-goes-wrong","title":"When Something Goes Wrong","text":"<p>In most cases, we think <code>Tabbed</code> will work out-of-the-box on your text files but the variability in dialects and structures means we can't guarantee it. <code>Tabbed</code> provides several fallbacks to help you read files when something has gone wrong. Specifically there are two problems you may encounter:</p> <p>Incorrect Start Row</p> <p>If tab fails to detect the file's structure, the start row for the read will be incorrect. You have 2 options to deal with this.</p> <ul> <li>Adjust the <code>start</code>, <code>amount</code>, or <code>skips</code>attributes of the sniffer or the   exclude parameter of the header and metadata sniffer methods.  These   control the sample the sniffer uses to detect the header and metadata if   they exist. You can use <code>Reader.peek</code> to help you determine good values   for these parameters.</li> <li>Adjust the default <code>poll</code> and <code>exclude</code> arguments of a Reader instance. In   particular, the <code>exclude</code> argument can be used to ignore missing values   for better type inference.</li> <li>During Read, set the <code>start</code> parameter to force reading to begin at   a specific row.  This will also require you to manually set the reader's   header by setting <code>reader.header</code> to a list of header string names. This   method should always work when structure (metadata, header, etc) isn't   being detected.</li> </ul> <p>Wonky Data Values</p> <p>Tabbed supports reading <code>ints</code>, <code>floats</code>, <code>complex</code>, <code>time</code>, <code>date</code> and <code>datetime</code> types.  It further assumes that these types are consistent across rows within a column in the data section. If Tabbed encounters a type  conversion error, it gracefully returns the value as a string type and  logs the error to the <code>Reader.errors</code> attribute. You can use this log to figure out what rows had problems and skip them or change the values using your own callable after they have been read by Tabbed.</p>"},{"location":"installation/","title":"Installation","text":"<p>Tabbed is available on pypi and can be installed into a virtual environment with <code>pip</code>. If your new to python package installation and need help creating a virtual environment you'll want to check out python's builtin venv OR  miniconda.</p> <pre><code>pip install tabbed\n</code></pre> <p>To get a development version of <code>Tabbed</code> from source start by cloning the repository</p> <pre><code>git clone git@github.com:mscaudill/tabbed.git\n</code></pre> <p>Go to the directory you just cloned and create an editable install with pip. <pre><code>pip install -e .[dev]\n</code></pre></p>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>Tabbed relies on clevercsv and Python &gt;= 3.11. <code>pip</code> will fetch these dependencies for you automatically.</p>"},{"location":"reference/parsing/","title":"Parsing","text":"<p>A module for detecting &amp; converting strings to python types supported by Tabbed. These tools are wrapped by the <code>convert</code> function which dispatches a string to a type specific convert callable.</p>"},{"location":"reference/parsing/#tabbed.utils.parsing.convert","title":"<code>tabbed.utils.parsing.convert(astring, decimal='.', celltype=None, fmt=None)</code>","text":"<p>Attempts to convert a string to a valid Cell type.</p> <p>Tabbed supports string conversion of each row's elements to the following types:</p> <pre><code>- str\n- int\n- float\n- complex\n- time\n- date\n- datetime\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string that possibly represents a CellType, one of int, float, complex, datetime or string.</p> required <code>decimal</code> <code>str</code> <p>A string that represents the decimal notation for numeric types.</p> <code>'.'</code> <code>celltype</code> <code>type[CellType] | None</code> <p>A CellType callable class, one of int, float, complex, str, time, date or datetime. If None, automatic and slower conversion of astring will be attempted.</p> <code>None</code> <code>fmt</code> <code>str | None</code> <p>A datetime format required by time, date and datetime celltypes. If None, automatic conversion of astring will be attempted.</p> <code>None</code> <p>Returns:</p> Type Description <code>CellType</code> <p>A CellType</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if celltype is provided and conversion fails.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def convert(\n    astring: str,\n    decimal: str = '.',\n    celltype: type[CellType] | None = None,\n    fmt: str | None = None,\n) -&gt; CellType:\n    \"\"\"Attempts to convert a string to a valid Cell type.\n\n    Tabbed supports string conversion of each row's elements to the following types:\n\n        - str\n        - int\n        - float\n        - complex\n        - time\n        - date\n        - datetime\n\n    Args:\n        astring:\n            A string that possibly represents a CellType, one of int, float,\n            complex, datetime or string.\n        decimal:\n            A string that represents the decimal notation for numeric types.\n        celltype:\n            A CellType callable class, one of int, float, complex, str, time,\n            date or datetime. If None, automatic and slower conversion of\n            astring will be attempted.\n        fmt:\n            A datetime format required by time, date and datetime celltypes. If\n            None, automatic conversion of astring will be attempted.\n\n    Returns:\n        A CellType\n\n    Raises:\n        ValueError: if celltype is provided and conversion fails.\n    \"\"\"\n\n    if celltype and fmt:\n        adatetime = datetime.strptime(astring, fmt)\n        if celltype == datetime:\n            return adatetime\n        # avoid instance assertions for speed here\n        # we know this should be a date or time instance\n        return getattr(  # type: ignore[no-any-return]\n            adatetime, celltype.__name__\n        )()\n\n    # replace decimal notation with dot notation\n    if celltype in {float, complex, int}:\n        try:\n            return celltype(astring)  # type: ignore[call-arg, arg-type]\n        except ValueError:\n            astring = astring.replace(decimal, '.')\n            return celltype(astring)  # type: ignore[call-arg, arg-type]\n\n    if celltype == str:\n        return astring\n\n    # numeric\n    if is_numeric(astring, decimal):\n        return as_numeric(astring, decimal)\n\n    # simple string a subset of ascii\n    if set(astring.lower()).issubset(string.ascii_letters):\n        return astring\n\n    # times,dates, datetimes - use asserts for mypy type narrowing\n    if is_time(astring):\n        fmt = find_format(astring, time_formats())\n        assert isinstance(fmt, str)\n        return as_time(astring, fmt)\n\n    if is_date(astring):\n        fmt = find_format(astring, date_formats())\n        assert isinstance(fmt, str)\n        return as_date(astring, fmt)\n\n    if is_datetime(astring):\n        # perform datetime last since it has many fmts to test\n        fmt = find_format(astring, datetime_formats())\n        assert isinstance(fmt, str)\n        return as_datetime(astring, fmt)\n\n    return astring\n</code></pre>"},{"location":"reference/parsing/#time-date-formats","title":"TIME &amp; DATE FORMATS","text":"<p>These functions define the date/time-like formats that Tabbed can detect and should be modified as new formats are encountered. </p>"},{"location":"reference/parsing/#tabbed.utils.parsing.time_formats","title":"<code>tabbed.utils.parsing.time_formats()</code>","text":"<p>Creates commonly used time format specifiers.</p> <p>This function returns many common time formats but not all. As new formats are encountered this function should be modified.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of time format specifiers for datetime's strptime method.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def time_formats() -&gt; list[str]:\n    \"\"\"Creates commonly used time format specifiers.\n\n    This function returns many common time formats but not all. As new formats\n    are encountered this function should be modified.\n\n    Returns:\n        A list of time format specifiers for datetime's strptime method.\n    \"\"\"\n\n    fmts = []\n    hours, microsecs = ['I', 'H'], ['', ':%f', '.%f']\n    diurnal = '%p'\n    for hrs, micro in itertools.product(hours, microsecs):\n        if hrs == 'I':\n            # If 12 hour clock allow for possible space before am/pm\n            fmts.append(f'%{hrs}:%M:%S{micro}{diurnal}')\n            fmts.append(f'%{hrs}:%M:%S{micro} {diurnal}')\n        else:\n            fmts.append(f'%{hrs}:%M:%S{micro}')\n\n    return fmts\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.date_formats","title":"<code>tabbed.utils.parsing.date_formats()</code>","text":"<p>Creates commonly used date format specifiers.</p> <p>This function returns many common date formats but not all. As new formats are encountered this function should be modified to detect more.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of date formats specifiers for datetime's strptime method.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def date_formats() -&gt; list[str]:\n    \"\"\"Creates commonly used date format specifiers.\n\n    This function returns many common date formats but not all. As new formats\n    are encountered this function should be modified to detect more.\n\n    Returns:\n        A list of date formats specifiers for datetime's strptime method.\n    \"\"\"\n\n    months, separators, years = 'mbB', ' /-.', 'Yy'\n    fmts = []\n    for mth, sep, yr in itertools.product(months, separators, years):\n        # build month and day first fmts\n        x = [f'%{mth}{sep}%d{sep}%{yr}', f'%d{sep}%{mth}{sep}%{yr}']\n        fmts.extend(x)\n\n    return fmts\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.datetime_formats","title":"<code>tabbed.utils.parsing.datetime_formats()</code>","text":"<p>Creates commonly used datetime format specifiers.</p> <p>This function returns many common datetime formats but not all. As new formats are encountered the functions date_formats and time_formats should be modified.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of datetime formats specifiers for datetime's strptime method.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def datetime_formats() -&gt; list[str]:\n    \"\"\"Creates commonly used datetime format specifiers.\n\n    This function returns many common datetime formats but not all. As new\n    formats are encountered the functions date_formats and time_formats should\n    be modified.\n\n    Returns:\n        A list of datetime formats specifiers for datetime's strptime method.\n    \"\"\"\n\n    datefmts, timefmts = date_formats(), time_formats()\n    fmts = []\n    for datefmt, timefmt in itertools.product(datefmts, timefmts):\n        fmts.append(' '.join([datefmt, timefmt]))\n\n    return fmts\n</code></pre>"},{"location":"reference/parsing/#time-date-detection","title":"TIME &amp; DATE DETECTION","text":"<p>These functions determine if a string is a date/time-like and locate the correct python format string.</p>"},{"location":"reference/parsing/#tabbed.utils.parsing.is_time","title":"<code>tabbed.utils.parsing.is_time(astring)</code>","text":"<p>Test if astring represents a time.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string that possibly represents a time.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if astring can be converted to a datetime and False otherwise.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def is_time(astring: str) -&gt; bool:\n    \"\"\"Test if astring represents a time.\n\n    Args:\n        astring:\n            A string that possibly represents a time.\n\n    Returns:\n        True if astring can be converted to a datetime and False otherwise.\n    \"\"\"\n\n    # all times contain 2 ':' separators\n    if Counter(astring)[':'] &lt; 2:\n        return False\n\n    # another method to time detect without fmt testing could give speedup\n    fmt = find_format(astring, time_formats())\n    return bool(fmt)\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.is_date","title":"<code>tabbed.utils.parsing.is_date(astring)</code>","text":"<p>Test if astring represents a date.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string instance that possibly represents a datetime instance.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if astring can be converted to a datetime and False otherwise.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def is_date(astring: str) -&gt; bool:\n    \"\"\"Test if astring represents a date.\n\n    Args:\n        astring:\n            A string instance that possibly represents a datetime instance.\n\n    Returns:\n        True if astring can be converted to a datetime and False otherwise.\n    \"\"\"\n\n    # another method to date detect without fmt testing could give speedup\n    fmt = find_format(astring, date_formats())\n    return bool(fmt)\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.is_datetime","title":"<code>tabbed.utils.parsing.is_datetime(astring)</code>","text":"<p>Test if astring represents a datetime.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string that possibly represents a datetime.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if astring can be converted to a datetime and False otherwise.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def is_datetime(astring: str) -&gt; bool:\n    \"\"\"Test if astring represents a datetime.\n\n    Args:\n        astring:\n            A string that possibly represents a datetime.\n\n    Returns:\n        True if astring can be converted to a datetime and False otherwise.\n    \"\"\"\n\n    # another method to datetime detect without fmt testing could give speedup\n    fmt = find_format(astring, datetime_formats())\n    return bool(fmt)\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.find_format","title":"<code>tabbed.utils.parsing.find_format(astring, formats)</code>","text":"<p>Returns the date, time, or datetime format of astring.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string instance that possibly represents a date, a time, or a datetime.</p> required <code>formats</code> <code>list[str]</code> <p>A list of formats to try to convert astring with. See date_formats, time_formats and datetime_formats functions of this module.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>A format string or None.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def find_format(astring: str, formats: list[str]) -&gt; str | None:\n    \"\"\"Returns the date, time, or datetime format of astring.\n\n    Args:\n        astring:\n            A string instance that possibly represents a date, a time, or\n            a datetime.\n        formats:\n            A list of formats to try to convert astring with. See date_formats,\n            time_formats and datetime_formats functions of this module.\n\n    Returns:\n        A format string or None.\n    \"\"\"\n\n    for fmt in formats:\n        try:\n            datetime.strptime(astring, fmt)\n            return fmt\n        except ValueError:\n            continue\n\n    return None\n</code></pre>"},{"location":"reference/parsing/#time-date-conversion","title":"TIME &amp; DATE CONVERSION","text":""},{"location":"reference/parsing/#tabbed.utils.parsing.as_time","title":"<code>tabbed.utils.parsing.as_time(astring, fmt)</code>","text":"<p>Converts astring representing a time into a datetime time instance.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string representing a time.</p> required <p>Returns:</p> Type Description <code>time | str</code> <p>A datetime.time instance or astring on conversion failure</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def as_time(astring: str, fmt: str) -&gt; time | str:\n    \"\"\"Converts astring representing a time into a datetime time instance.\n\n    Args:\n        astring:\n            A string representing a time.\n\n    Returns:\n        A datetime.time instance or astring on conversion failure\n    \"\"\"\n\n    try:\n        return datetime.strptime(astring, fmt).time()\n    except ValueError:\n        return astring\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.as_date","title":"<code>tabbed.utils.parsing.as_date(astring, fmt)</code>","text":"<p>Converts astring representing a date into a datetime date instance.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string representing a date.</p> required <p>Returns:</p> Type Description <code>date | str</code> <p>A datetime.date instance or astring on conversion failure</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def as_date(astring: str, fmt: str) -&gt; date | str:\n    \"\"\"Converts astring representing a date into a datetime date instance.\n\n    Args:\n        astring:\n            A string representing a date.\n\n    Returns:\n        A datetime.date instance or astring on conversion failure\n    \"\"\"\n\n    try:\n        return datetime.strptime(astring, fmt).date()\n    except ValueError:\n        return astring\n</code></pre>"},{"location":"reference/parsing/#tabbed.utils.parsing.as_datetime","title":"<code>tabbed.utils.parsing.as_datetime(astring, fmt)</code>","text":"<p>Converts astring representing datetime into a datetime instance.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string representing a datetime.</p> required <p>Returns:</p> Type Description <code>datetime | str</code> <p>A datetime instance or astring on conversion failure</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def as_datetime(astring: str, fmt: str) -&gt; datetime | str:\n    \"\"\"Converts astring representing datetime into a datetime instance.\n\n    Args:\n        astring:\n            A string representing a datetime.\n\n    Returns:\n        A datetime instance or astring on conversion failure\n    \"\"\"\n\n    try:\n        return datetime.strptime(astring, fmt)\n    except ValueError:\n        return astring\n</code></pre>"},{"location":"reference/parsing/#numeric-conversion","title":"NUMERIC CONVERSION","text":"<p>Function for converting string to a Tabbed numeric type; int, float, or complex. </p>"},{"location":"reference/parsing/#tabbed.utils.parsing.as_numeric","title":"<code>tabbed.utils.parsing.as_numeric(astring, decimal)</code>","text":"<p>Converts astring representing a numeric into an int, float or complex.</p> <p>Parameters:</p> Name Type Description Default <code>astring</code> <code>str</code> <p>A string that represents a numeric type.</p> required <code>decimal</code> <code>str</code> <p>A string representing the decimal notation.</p> required <p>Returns:</p> Type Description <code>int | float | complex | str</code> <p>A numeric type but on conversion failure returns input string.</p> Source code in <code>src/tabbed/utils/parsing.py</code> <pre><code>def as_numeric(astring: str, decimal: str) -&gt; int | float | complex | str:\n    \"\"\"Converts astring representing a numeric into an int, float or complex.\n\n    Args:\n        astring:\n            A string that represents a numeric type.\n        decimal:\n            A string representing the decimal notation.\n\n    Returns:\n        A numeric type but on conversion failure returns input string.\n    \"\"\"\n\n    if decimal != '.':\n        astring = astring.replace(decimal, '.')\n\n    # look for imag part for complex\n    if re.findall(r'[ij]', astring):\n        return complex(astring)\n\n    # look for a decimal\n    if re.findall(r'\\.', astring):\n        return float(astring)\n\n    try:\n        return int(astring)\n    except ValueError:\n        return astring\n</code></pre>"},{"location":"reference/reading/","title":"Reading","text":""},{"location":"reference/reading/#tabbed.reading","title":"<code>tabbed.reading</code>","text":"<p>A reader of text delimited files that supports the following features:</p> <ul> <li>Identification of metadata &amp; header file sections.</li> <li>Automated type conversion to ints, floats, complex numbers,   times, dates and datetime instances.</li> <li>Selective reading of rows and columns satisfying equality,   membership, regular expression, and rich comparison conditions.</li> <li>Iterative reading of rows from the input file.</li> </ul>"},{"location":"reference/reading/#tabbed.reading.Reader","title":"<code>tabbed.reading.Reader</code>","text":"<p>               Bases: <code>ReprMixin</code></p> <p>An iterative reader of irregular text files supporting selective value-based reading of rows and columns.</p> <p>A common variant to the RFC-4180 CSV standard includes metadata prior to a possible header and data section. This reader sniffs files for these sections advancing to the most-likely start position of the data. Additionally, it uses type inference to automatically convert data cells into strings, integers, floats, complex, time, date or datetime instances. Finally, this reader supports selective reading of rows using equality, membership, comparison, &amp; regular expression value-based conditions supplied as keyword arguments to the 'tab' method.</p> <p>Attributes:</p> Name Type Description <code>infile</code> <p>An I/O stream instance returned by open.</p> <code>tabulator</code> <p>A callable container of Tab instances; callables that will filter rows based on equality, membership, rich comparison and regular expression conditions.</p> <code>errors</code> <p>A container of casting and ragged length errors detected during reading.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create a temporary file for reading\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import random\n&gt;&gt;&gt; from datetime import datetime, timedelta\n&gt;&gt;&gt; # make metadata that spans several lines\n&gt;&gt;&gt; metadata_string = ('Experiment, 3\\n'\n... 'Name, Ernst Rutherford\\n'\n... 'location, Cavendish Labs\\n'\n... 'Time, 11:03:29.092\\n'\n... 'Date, 8/23/1917\\n'\n... '\\n')\n&gt;&gt;&gt; # make a header of 5 columns\n&gt;&gt;&gt; header = ['group', 'count', 'color', 'time', 'area']\n&gt;&gt;&gt; header_string = ','.join(header) + '\\n'\n&gt;&gt;&gt; # make a reproducible data section with 20 rows\n&gt;&gt;&gt; random.seed(0)\n&gt;&gt;&gt; groups = random.choices(['a', 'b', 'c'], k=20)\n&gt;&gt;&gt; counts = [str(random.randint(0, 10)) for _ in range(20)]\n&gt;&gt;&gt; colors = random.choices(['red', 'green', 'blue'], k=20)\n&gt;&gt;&gt; start = datetime(1917, 8, 23, 11, 3, 29, 9209)\n&gt;&gt;&gt; times = [str(start + timedelta(seconds=10*i)) for i in range(20)]\n&gt;&gt;&gt; areas = [str(random.uniform(0, 10)) for _ in range(20)]\n&gt;&gt;&gt; x = [','.join(row) for row in zip(\n...    groups, counts, colors, times, areas)]\n&gt;&gt;&gt; data_string = '\\r\\n'.join(x)\n&gt;&gt;&gt; # write the metadata, header and data strings\n&gt;&gt;&gt; fp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n&gt;&gt;&gt; _ = fp.write(metadata_string)\n&gt;&gt;&gt; _ = fp.write(header_string)\n&gt;&gt;&gt; _ = fp.write(data_string)\n&gt;&gt;&gt; fp.close()\n&gt;&gt;&gt; # open the file for reading\n&gt;&gt;&gt; infile = open(fp.name, mode='r')\n&gt;&gt;&gt; reader = Reader(infile)\n&gt;&gt;&gt; # ask the reader for the header\n&gt;&gt;&gt; reader.header\n...\nHeader(line=6,\nnames=['group', 'count', 'color', 'time', 'area'],\nstring='group,count,color,time,area')\n&gt;&gt;&gt; # read group, count &amp; area columns where group is a or c &amp; 0 &lt; area &lt;=4\n&gt;&gt;&gt; # by passing keyword args to this reader's 'tab' method\n&gt;&gt;&gt; reader.tab(columns=['group', 'count', 'area'],\n... group=['a', 'c'],\n... area='&gt; 0 and &lt;= 4')\n&gt;&gt;&gt; # read the data with a chunksize of 3 rows\n&gt;&gt;&gt; rows = reader.read(chunksize=3)\n&gt;&gt;&gt; type(rows) # rows are of type generator yielding 3 rows at a time\n&lt;class 'generator'&gt;\n&gt;&gt;&gt; for idx, chunk in enumerate(rows):\n...     print(f'Index = {idx}\\n{chunk}')\n...\nIndex = 0\n[{'group': 'c', 'count': 4, 'area': 3.2005460467254574},\n{'group': 'a', 'count': 10, 'area': 1.0905784593110368},\n{'group': 'c', 'count': 7, 'area': 2.90329502402758}]\nIndex = 1\n[{'group': 'c', 'count': 8, 'area': 1.8939132855435614},\n{'group': 'c', 'count': 4, 'area': 1.867295282555551}]\n&gt;&gt;&gt; # close reader since it was not opened with context manager\n&gt;&gt;&gt; reader.close()\n&gt;&gt;&gt; os.remove(fp.name) # explicitly remove the tempfile\n</code></pre> Source code in <code>src/tabbed/reading.py</code> <pre><code>class Reader(ReprMixin):\n    r\"\"\"An iterative reader of irregular text files supporting selective\n    value-based reading of rows and columns.\n\n    A common variant to the RFC-4180 CSV standard includes metadata prior to\n    a possible header and data section. This reader sniffs files for these\n    sections advancing to the most-likely start position of the data.\n    Additionally, it uses type inference to automatically convert data cells\n    into strings, integers, floats, complex, time, date or datetime instances.\n    Finally, this reader supports selective reading of rows using equality,\n    membership, comparison, &amp; regular expression value-based conditions supplied\n    as keyword arguments to the 'tab' method.\n\n    Attributes:\n        infile:\n            An I/O stream instance returned by open.\n        tabulator:\n            A callable container of Tab instances; callables that will filter\n            rows based on equality, membership, rich comparison and regular\n            expression conditions.\n        errors:\n            A container of casting and ragged length errors detected during\n            reading.\n\n    Examples:\n        &gt;&gt;&gt; # Create a temporary file for reading\n        &gt;&gt;&gt; import os\n        &gt;&gt;&gt; import tempfile\n        &gt;&gt;&gt; import random\n        &gt;&gt;&gt; from datetime import datetime, timedelta\n        &gt;&gt;&gt; # make metadata that spans several lines\n        &gt;&gt;&gt; metadata_string = ('Experiment, 3\\n'\n        ... 'Name, Ernst Rutherford\\n'\n        ... 'location, Cavendish Labs\\n'\n        ... 'Time, 11:03:29.092\\n'\n        ... 'Date, 8/23/1917\\n'\n        ... '\\n')\n        &gt;&gt;&gt; # make a header of 5 columns\n        &gt;&gt;&gt; header = ['group', 'count', 'color', 'time', 'area']\n        &gt;&gt;&gt; header_string = ','.join(header) + '\\n'\n        &gt;&gt;&gt; # make a reproducible data section with 20 rows\n        &gt;&gt;&gt; random.seed(0)\n        &gt;&gt;&gt; groups = random.choices(['a', 'b', 'c'], k=20)\n        &gt;&gt;&gt; counts = [str(random.randint(0, 10)) for _ in range(20)]\n        &gt;&gt;&gt; colors = random.choices(['red', 'green', 'blue'], k=20)\n        &gt;&gt;&gt; start = datetime(1917, 8, 23, 11, 3, 29, 9209)\n        &gt;&gt;&gt; times = [str(start + timedelta(seconds=10*i)) for i in range(20)]\n        &gt;&gt;&gt; areas = [str(random.uniform(0, 10)) for _ in range(20)]\n        &gt;&gt;&gt; x = [','.join(row) for row in zip(\n        ...    groups, counts, colors, times, areas)]\n        &gt;&gt;&gt; data_string = '\\r\\n'.join(x)\n        &gt;&gt;&gt; # write the metadata, header and data strings\n        &gt;&gt;&gt; fp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n        &gt;&gt;&gt; _ = fp.write(metadata_string)\n        &gt;&gt;&gt; _ = fp.write(header_string)\n        &gt;&gt;&gt; _ = fp.write(data_string)\n        &gt;&gt;&gt; fp.close()\n        &gt;&gt;&gt; # open the file for reading\n        &gt;&gt;&gt; infile = open(fp.name, mode='r')\n        &gt;&gt;&gt; reader = Reader(infile)\n        &gt;&gt;&gt; # ask the reader for the header\n        &gt;&gt;&gt; reader.header\n        ... # doctest: +NORMALIZE_WHITESPACE\n        Header(line=6,\n        names=['group', 'count', 'color', 'time', 'area'],\n        string='group,count,color,time,area')\n        &gt;&gt;&gt; # read group, count &amp; area columns where group is a or c &amp; 0 &lt; area &lt;=4\n        &gt;&gt;&gt; # by passing keyword args to this reader's 'tab' method\n        &gt;&gt;&gt; reader.tab(columns=['group', 'count', 'area'],\n        ... group=['a', 'c'],\n        ... area='&gt; 0 and &lt;= 4')\n        &gt;&gt;&gt; # read the data with a chunksize of 3 rows\n        &gt;&gt;&gt; rows = reader.read(chunksize=3)\n        &gt;&gt;&gt; type(rows) # rows are of type generator yielding 3 rows at a time\n        &lt;class 'generator'&gt;\n        &gt;&gt;&gt; for idx, chunk in enumerate(rows):\n        ...     print(f'Index = {idx}\\n{chunk}')\n        ...     # doctest: +NORMALIZE_WHITESPACE\n        Index = 0\n        [{'group': 'c', 'count': 4, 'area': 3.2005460467254574},\n        {'group': 'a', 'count': 10, 'area': 1.0905784593110368},\n        {'group': 'c', 'count': 7, 'area': 2.90329502402758}]\n        Index = 1\n        [{'group': 'c', 'count': 8, 'area': 1.8939132855435614},\n        {'group': 'c', 'count': 4, 'area': 1.867295282555551}]\n        &gt;&gt;&gt; # close reader since it was not opened with context manager\n        &gt;&gt;&gt; reader.close()\n        &gt;&gt;&gt; os.remove(fp.name) # explicitly remove the tempfile\n    \"\"\"\n\n    # no mutation of exclude parameter\n    # pylint: disable-next=dangerous-default-value\n    def __init__(\n        self,\n        infile: IO[str],\n        poll: int = 20,\n        exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n        decimal: str = '.',\n        **sniffing_kwargs,\n    ) -&gt; None:\n        \"\"\"Initialize this Reader.\n\n        Args:\n            infile:\n                An IO stream instance returned by open builtin.\n            poll:\n                The number of last sample rows to use for the Sniffer to detect\n                header, metadata and data types. For optimal detection of the\n                header and metadata file components, the poll should be not\n                include rows that could be header or metadata.\n            exclude:\n               A sequence of characters indicating missing values in the file.\n               Rows containing these values will be disqualified from use for\n               header, metadata and data type detection. However, this Reader's\n               read method will still read and return rows with this exclusion\n               values.\n            sniffing_kwargs:\n                Any valid kwarg for a tabbed Sniffer instance including: start,\n                amount, skips and delimiters. Please see Sniffer initializer.\n\n        Notes:\n            During initialization, this reader will use the poll and exclude\n            arguments to make an initial guess of the header. If this guess is\n            wrong, the header may be explicitly set via the 'header' setter\n            property.\n        \"\"\"\n\n        self.infile = infile\n        self.decimal = decimal\n        self._sniffer = Sniffer(infile, decimal=decimal, **sniffing_kwargs)\n        self.poll = poll\n        self.exclude = exclude\n        self._header = self._sniffer.header(self.poll, self.exclude)\n        self.tabulator = Tabulator(self.header, columns=None, tabs=None)\n        self.errors = SimpleNamespace(casting=[], ragged=[])\n\n    @property\n    def sniffer(self) -&gt; Sniffer:\n        \"\"\"Returns this Reader's sniffer instance.\n\n        Any time the sniffer is accessed we reset this reader's header and\n        tabulator if the header is built by the sniffer.\n        \"\"\"\n\n        if self._header.line is not None:\n            # print('Resniffing Header and resetting metadata and Tabulator')\n            self._header = self._sniffer.header(self.poll, self.exclude)\n            self.tabulator = Tabulator(self.header, columns=None, tabs=None)\n\n        return self._sniffer\n\n    @property\n    def header(self) -&gt; Header:\n        \"\"\"Fetches this Reader's current header.\"\"\"\n\n        return self._header\n\n    @header.setter\n    def header(self, value: int | list[str] | dict) -&gt; None:\n        \"\"\"Sets this Reader's header and resets the metadata and Tabulator.\n\n        Args:\n            value:\n                An infile line number, list of string names, or dict of keyword\n                arguments for sniffer's header method. If value is type int, the\n                header will be set to the split string values of the value row\n                of infile. If value is type List, the header will be set to the\n                string names in value. If value is type dict, the header will be\n                resniffed by sniffer's header method using value keyword args.\n                Valid keyword arguments are: 'poll', and 'exclude'. Please type\n                help(reader.sniffer.header) for more argument details.\n\n        Returns:\n            None\n\n        Raises:\n            A ValueError is issued if value is int or List type and the length\n            of the proposed header names does not match the length of the last\n            sample row in the sniffer.\n        \"\"\"\n\n        # get the expected length of the header from the last sample row.\n        expected = len(self._sniffer.rows[-1])\n\n        if isinstance(value, int):\n            sniff = Sniffer(self.infile, start=value, amount=1)\n            if len(sniff.rows[0]) != expected:\n                msg = (\n                    f'Length of row at index = {value} does not match'\n                    f'length of last sample row = {expected}'\n                )\n                raise ValueError(msg)\n            result = Header(value, sniff.rows[0], sniff.sample)\n\n        elif isinstance(value, list):\n            if len(value) != expected:\n                msg = (\n                    f'Length of provided header names = {len(value)} does '\n                    f'not match length of last sample row = {expected}'\n                )\n                raise ValueError(msg)\n            result = Header(None, value, None)\n\n        elif isinstance(value, dict):\n            result = self._sniffer.header(**value)\n\n        else:\n            msg = (\n                \"A header may be set by integer line number, list of \"\n                \"header names or a dict of kwargs for sniffer's header \"\n                f\"method but not type {type(value)}.\"\n            )\n            raise ValueError(msg)\n\n        # set header\n        self._header = result\n        # determine if reader has previously set tabulator and warn\n        previous = self.tabulator\n        tblr = Tabulator(self.header, tabs=None, columns=None)\n        if tblr.columns != previous.columns or tblr.tabs != previous.tabs:\n            msg = (\n                \"Previously set tabs have been reset. Please call 'tab' \"\n                \"method again before reading.\"\n            )\n            print(msg)\n\n        self.tabulator = tblr\n\n    def metadata(self) -&gt; MetaData:\n        \"\"\"Returns this Reader's current metadata.\n\n        Returns:\n            A sniffed metadata instance.\n        \"\"\"\n\n        return self._sniffer.metadata(self.header, self.poll, self.exclude)\n\n    def tab(\n        self,\n        columns: list[str] | list[int] | re.Pattern | None = None,\n        **tabs: (\n            CellType\n            | Sequence[CellType]\n            | re.Pattern\n            | Callable[[dict[str, CellType], str], bool]\n        ),\n    ) -&gt; None:\n        \"\"\"Set the Tabulator instance that will filter infile's rows &amp; columns.\n\n        A tabulator is a container of tab instances that when called on a row,\n        sequentially applies each tab to that row. Additionally after applying\n        the row tabs it filters the result by columns. Implementation details\n        may be found in the tabbed.tabs module.\n\n        Args:\n            columns:\n                Columns in each row to return during reading as a list of string\n                names, a list of column indices or a compiled regular expression\n                pattern to match against header names. If None, all the columns\n                in the header will be read during a read call.\n            tabs:\n                name = value keyword argument pairs where name is a valid header\n                column name and value may be of type string, int, float,\n                complex, time, date, datetime, regular expression or callable.\n\n                - If a string type with rich comparison(s) is provided,\n                  a comparison tab is constructed.\n                - If a string, int, float, complex, time, date  or datetime is\n                  provided, an equality tab is constructed.\n                - If a sequence is provided, a membership tab is constructed.\n                - If a compiled re pattern, a Regex tab is constructed. See\n                  class docs for example.\n\n        Notes:\n            If the value in a tab is a numeric or is a string representation of\n            a numeric it must use a '.' decimal as Tabbed converts ',' decimal\n            notation to '.' notation for consistency.\n\n        Returns:\n            None\n        \"\"\"\n\n        self.tabulator = tabbing.Tabulator.from_keywords(\n            self.header, columns, **tabs\n        )\n\n    def _log_ragged(self, line, row, raise_error):\n        \"\"\"Error logs rows whose length is unexpected.\n\n        When python's csv DictReader encounters a row with more cells than\n        header columns, it stores the additional cells to a list under the None\n        key.  When the csv DictReader encounters a row that with fewer cells\n        than header columns it inserts None values into the missing cells. This\n        function detects rows with None keys or None values and logs the row\n        number to the error log.\n\n        Args:\n            line:\n                The line number of the row being tested.\n            row:\n                A row dictionary of header names and casted values.\n            raise_error:\n                A boolean indicating if ragged should raise an error and stop\n                the reading of the file if a ragged row is encountered.\n\n        Returns:\n            The row with None restkey popped\n        \"\"\"\n\n        remainder = row.pop(None, None)\n        none_vals = None in row.values()\n\n        if remainder is not None or none_vals:\n            msg = f'Unexpected line length on row {line}'\n            if raise_error:\n                raise csv.Error(msg)\n            self.errors.ragged.append(msg)\n\n        return row\n\n    def _prime(\n        self,\n        start: int | None = None,\n        indices: Sequence | None = None,\n    ) -&gt; tuple[Iterator, int]:\n        \"\"\"Prime this Reader for reading by constructing a row iterator.\n\n        Args:\n            start:\n                An integer line number from the start of the file to begin\n                reading data. If None and this reader's header has a line\n                number, the line following the header line is the start. If None\n                and the header line is None, the line following the metadata\n                section is the start. If None and the file has no header or\n                metadata, start is 0. If indices are provided, this argument is\n                ignored.\n            indices:\n                An optional Sequence of line numbers to read rows relative to\n                the start of the file. If None, all rows from start not in skips\n                will be read. If reading a slice of the file, a range instance\n                will have improved performance over list or tuple sequence\n                types.\n\n        Notes:\n            A warning is issued if the start or index start is less than the\n            detected start of the datasection.\n\n        Returns:\n            A row iterator &amp; row index the iterator starts from.\n\n        Raises:\n            A ValueError is issued if start and indices are provided and the\n            first index is less than start.\n        \"\"\"\n\n        # locate the start of the datasection\n        autostart = 0\n        if self.header.line is not None:\n            autostart = self.header.line + 1\n        else:\n            metalines = self._sniffer.metadata(\n                None, self.poll, self.exclude\n            ).lines\n            autostart = metalines[1] + 1 if metalines[1] else metalines[0]\n\n        astart = start if start is not None else autostart\n        stop = None\n        step = None\n\n        # indices if provided override start, stop and step\n        if indices:\n\n            if isinstance(indices, range):\n                astart, stop, step = indices.start, indices.stop, indices.step\n\n            elif isinstance(indices, Sequence):\n                astart, stop = indices[0], indices[-1] + 1\n\n                if start and astart &lt; start:\n                    msg = (\n                        f'The first indexed line to read = {astart} is &lt; '\n                        f'the start line = {start}!'\n                    )\n                    raise ValueError(msg)\n\n            else:\n                msg = f'indices must be a Sequence type not {type(indices)}.'\n                raise TypeError(msg)\n\n        # warn if start is &lt; computed autostart\n        if astart &lt; autostart:\n            msg = (\n                f'start = {astart} is &lt; than detected data start = {autostart}'\n            )\n            warnings.warn(msg)\n\n        # advance reader's infile to account for blank metalines &amp; get dialect\n        self.infile.seek(0)\n\n        # check that we have a valid simple dialect &amp; convert it\n        if not self._sniffer.dialect:\n            msg = (\n                \"Sniffer failed to detect dialect. Please set sniffer's\"\n                \"dialect attribute before calling read\"\n            )\n            raise csv.Error(msg)\n        assert isinstance(self._sniffer.dialect, SimpleDialect)\n        dialect = self._sniffer.dialect.to_csv_dialect()\n\n        # pylint: disable-next=expression-not-assigned\n        [next(self.infile) for _ in range(astart)]\n        row_iter = csv.DictReader(\n            self.infile,\n            self.header.names,\n            dialect=dialect,\n        )\n\n        stop = stop - astart if stop else None\n        return itertools.islice(row_iter, 0, stop, step), astart\n\n    # read method needs provide reasonable options for args\n    # pylint: disable-next=too-many-positional-arguments\n    def read(\n        self,\n        start: int | None = None,\n        skips: Sequence[int] | None = None,\n        indices: Sequence | None = None,\n        chunksize: int = int(2e5),\n        skip_empty: bool = True,\n        raise_ragged: bool = False,\n    ) -&gt; Iterator[list[dict[str, CellType]]]:\n        \"\"\"Iteratively read dictionary rows that satisfy this Reader's tabs.\n\n        Args:\n            start:\n                A line number from the start of the file to begin reading data\n                from. If None and this reader's header has a line number, the\n                line following the header is the start. If None and the header\n                line number is None, the line following the last line in the\n                metadata is the start. If None and there is no header or\n                metadata, the start line is 0.\n            skips:\n                A sequence of line numbers to skip during reading.\n            indices:\n                A sequence of line numbers to read rows from. If None. all rows\n                from start not in skips will be read. If attempting to read\n                a slice of a file a range instance may be provided and will have\n                improved performance over other sequence types like lists.\n            chunksize:\n                The number of data lines to read for each yield. Lower values\n                consume less memory. The default is 200,000 rows.\n            skip_empty:\n                A boolean indicating if rows with no values between the\n                delimiters should be skipped. Default is True.\n            raise_ragged:\n                Boolean indicating if a row with more or fewer columns than\n                expected should raise an error and stop reading. The default is\n                False. Rows with fewer columns than the header will have None\n                as  the fill value. Rows with more columns than the header will\n                have None keys.\n\n        Yields:\n            Chunksize number of dictionary rows with header names as keys.\n\n        Raises:\n            A csv.Error is issued if a ragged row is encountered and\n            raise_ragged is True. Casting problems do not raise errors but\n            gracefully return strings when encountered.\n\n            A ValueError is issued if start and indices are provided and the\n            first indexed line to read in indices is less than the line to start\n            reading from.\n        \"\"\"\n\n        skips = [] if not skips else skips\n\n        # poll types &amp; formats, inconsistencies will trigger casting error log\n        types, _ = self._sniffer.types(self.poll, self.exclude)\n        formats, _ = self._sniffer.datetime_formats(self.poll, self.exclude)\n        castings = dict(zip(self.header.names, zip(types, formats)))\n\n        # initialize casting and ragged row errors\n        self.errors.casting = []\n        self.errors.ragged = []\n\n        # construct a row iterator\n        row_iter, row_start = self._prime(start, indices)\n\n        fifo: deque[dict[str, CellType]] = deque()\n        for line, dic in enumerate(row_iter, row_start):\n\n            if line in skips:\n                continue\n\n            if indices and line not in indices:\n                continue\n\n            if not any(dic.values()) and skip_empty:\n                continue\n\n            # chk &amp; log raggedness\n            dic = self._log_ragged(line, dic, raise_ragged)\n\n            # perform casts, log errors &amp; filter with tabulator\n            arow = {}\n            for name, astr in dic.items():\n\n                casting, fmt = castings[name]\n                try:\n                    arow[name] = parsing.convert(\n                        astr, self.decimal, casting, fmt\n                    )\n                except (ValueError, OverflowError, TypeError):\n                    # on exception leave astr unconverted &amp; log casting error\n                    msg = f\"line = {line}, column = '{name}'\"\n                    self.errors.casting.append(msg)\n                    arow[name] = astr\n\n            # apply tabs to filter row\n            row = self.tabulator(arow)\n\n            if row:\n                fifo.append(row)\n\n            if len(fifo) &gt;= chunksize:\n                yield [fifo.popleft() for _ in range(chunksize)]\n\n        yield list(fifo)\n        self.infile.seek(0)\n\n    def peek(self, count: int = 10) -&gt; None:\n        \"\"\"Prints count number of lines from the first line of the file.\n\n        This method can be used to ensure this Reader identifies the correct\n        metadata, header and data start locations.\n\n        Args:\n            count:\n                The number of lines to print.\n\n        Returns:\n            None\n        \"\"\"\n\n        cnt = 0\n        while cnt &lt; count:\n            CRED = '\\033[91m'\n            CEND = '\\033[0m'\n            print(CRED + f'{cnt}' + CEND, next(self.infile).rstrip())\n            cnt += 1\n\n        self.infile.seek(0)\n\n    def close(self):\n        \"\"\"Closes this Reader's infile resource.\"\"\"\n\n        self.infile.close()\n</code></pre>"},{"location":"reference/reading/#tabbed.reading.Reader.sniffer","title":"<code>sniffer</code>  <code>property</code>","text":"<p>Returns this Reader's sniffer instance.</p> <p>Any time the sniffer is accessed we reset this reader's header and tabulator if the header is built by the sniffer.</p>"},{"location":"reference/reading/#tabbed.reading.Reader.header","title":"<code>header</code>  <code>property</code> <code>writable</code>","text":"<p>Fetches this Reader's current header.</p>"},{"location":"reference/reading/#tabbed.reading.Reader.__init__","title":"<code>__init__(infile, poll=20, exclude=['', ' ', '-', 'nan', 'NaN', 'NAN'], decimal='.', **sniffing_kwargs)</code>","text":"<p>Initialize this Reader.</p> <p>Parameters:</p> Name Type Description Default <code>infile</code> <code>IO[str]</code> <p>An IO stream instance returned by open builtin.</p> required <code>poll</code> <code>int</code> <p>The number of last sample rows to use for the Sniffer to detect header, metadata and data types. For optimal detection of the header and metadata file components, the poll should be not include rows that could be header or metadata.</p> <code>20</code> <code>exclude</code> <code>list[str]</code> <p>A sequence of characters indicating missing values in the file. Rows containing these values will be disqualified from use for header, metadata and data type detection. However, this Reader's read method will still read and return rows with this exclusion values.</p> <code>['', ' ', '-', 'nan', 'NaN', 'NAN']</code> <code>sniffing_kwargs</code> <p>Any valid kwarg for a tabbed Sniffer instance including: start, amount, skips and delimiters. Please see Sniffer initializer.</p> <code>{}</code> Notes <p>During initialization, this reader will use the poll and exclude arguments to make an initial guess of the header. If this guess is wrong, the header may be explicitly set via the 'header' setter property.</p> Source code in <code>src/tabbed/reading.py</code> <pre><code>def __init__(\n    self,\n    infile: IO[str],\n    poll: int = 20,\n    exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n    decimal: str = '.',\n    **sniffing_kwargs,\n) -&gt; None:\n    \"\"\"Initialize this Reader.\n\n    Args:\n        infile:\n            An IO stream instance returned by open builtin.\n        poll:\n            The number of last sample rows to use for the Sniffer to detect\n            header, metadata and data types. For optimal detection of the\n            header and metadata file components, the poll should be not\n            include rows that could be header or metadata.\n        exclude:\n           A sequence of characters indicating missing values in the file.\n           Rows containing these values will be disqualified from use for\n           header, metadata and data type detection. However, this Reader's\n           read method will still read and return rows with this exclusion\n           values.\n        sniffing_kwargs:\n            Any valid kwarg for a tabbed Sniffer instance including: start,\n            amount, skips and delimiters. Please see Sniffer initializer.\n\n    Notes:\n        During initialization, this reader will use the poll and exclude\n        arguments to make an initial guess of the header. If this guess is\n        wrong, the header may be explicitly set via the 'header' setter\n        property.\n    \"\"\"\n\n    self.infile = infile\n    self.decimal = decimal\n    self._sniffer = Sniffer(infile, decimal=decimal, **sniffing_kwargs)\n    self.poll = poll\n    self.exclude = exclude\n    self._header = self._sniffer.header(self.poll, self.exclude)\n    self.tabulator = Tabulator(self.header, columns=None, tabs=None)\n    self.errors = SimpleNamespace(casting=[], ragged=[])\n</code></pre>"},{"location":"reference/reading/#tabbed.reading.Reader.metadata","title":"<code>metadata()</code>","text":"<p>Returns this Reader's current metadata.</p> <p>Returns:</p> Type Description <code>MetaData</code> <p>A sniffed metadata instance.</p> Source code in <code>src/tabbed/reading.py</code> <pre><code>def metadata(self) -&gt; MetaData:\n    \"\"\"Returns this Reader's current metadata.\n\n    Returns:\n        A sniffed metadata instance.\n    \"\"\"\n\n    return self._sniffer.metadata(self.header, self.poll, self.exclude)\n</code></pre>"},{"location":"reference/reading/#tabbed.reading.Reader.tab","title":"<code>tab(columns=None, **tabs)</code>","text":"<p>Set the Tabulator instance that will filter infile's rows &amp; columns.</p> <p>A tabulator is a container of tab instances that when called on a row, sequentially applies each tab to that row. Additionally after applying the row tabs it filters the result by columns. Implementation details may be found in the tabbed.tabs module.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list[str] | list[int] | Pattern | None</code> <p>Columns in each row to return during reading as a list of string names, a list of column indices or a compiled regular expression pattern to match against header names. If None, all the columns in the header will be read during a read call.</p> <code>None</code> <code>tabs</code> <code>CellType | Sequence[CellType] | Pattern | Callable[[dict[str, CellType], str], bool]</code> <p>name = value keyword argument pairs where name is a valid header column name and value may be of type string, int, float, complex, time, date, datetime, regular expression or callable.</p> <ul> <li>If a string type with rich comparison(s) is provided,   a comparison tab is constructed.</li> <li>If a string, int, float, complex, time, date  or datetime is   provided, an equality tab is constructed.</li> <li>If a sequence is provided, a membership tab is constructed.</li> <li>If a compiled re pattern, a Regex tab is constructed. See   class docs for example.</li> </ul> <code>{}</code> Notes <p>If the value in a tab is a numeric or is a string representation of a numeric it must use a '.' decimal as Tabbed converts ',' decimal notation to '.' notation for consistency.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/tabbed/reading.py</code> <pre><code>def tab(\n    self,\n    columns: list[str] | list[int] | re.Pattern | None = None,\n    **tabs: (\n        CellType\n        | Sequence[CellType]\n        | re.Pattern\n        | Callable[[dict[str, CellType], str], bool]\n    ),\n) -&gt; None:\n    \"\"\"Set the Tabulator instance that will filter infile's rows &amp; columns.\n\n    A tabulator is a container of tab instances that when called on a row,\n    sequentially applies each tab to that row. Additionally after applying\n    the row tabs it filters the result by columns. Implementation details\n    may be found in the tabbed.tabs module.\n\n    Args:\n        columns:\n            Columns in each row to return during reading as a list of string\n            names, a list of column indices or a compiled regular expression\n            pattern to match against header names. If None, all the columns\n            in the header will be read during a read call.\n        tabs:\n            name = value keyword argument pairs where name is a valid header\n            column name and value may be of type string, int, float,\n            complex, time, date, datetime, regular expression or callable.\n\n            - If a string type with rich comparison(s) is provided,\n              a comparison tab is constructed.\n            - If a string, int, float, complex, time, date  or datetime is\n              provided, an equality tab is constructed.\n            - If a sequence is provided, a membership tab is constructed.\n            - If a compiled re pattern, a Regex tab is constructed. See\n              class docs for example.\n\n    Notes:\n        If the value in a tab is a numeric or is a string representation of\n        a numeric it must use a '.' decimal as Tabbed converts ',' decimal\n        notation to '.' notation for consistency.\n\n    Returns:\n        None\n    \"\"\"\n\n    self.tabulator = tabbing.Tabulator.from_keywords(\n        self.header, columns, **tabs\n    )\n</code></pre>"},{"location":"reference/reading/#tabbed.reading.Reader.read","title":"<code>read(start=None, skips=None, indices=None, chunksize=int(200000.0), skip_empty=True, raise_ragged=False)</code>","text":"<p>Iteratively read dictionary rows that satisfy this Reader's tabs.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int | None</code> <p>A line number from the start of the file to begin reading data from. If None and this reader's header has a line number, the line following the header is the start. If None and the header line number is None, the line following the last line in the metadata is the start. If None and there is no header or metadata, the start line is 0.</p> <code>None</code> <code>skips</code> <code>Sequence[int] | None</code> <p>A sequence of line numbers to skip during reading.</p> <code>None</code> <code>indices</code> <code>Sequence | None</code> <p>A sequence of line numbers to read rows from. If None. all rows from start not in skips will be read. If attempting to read a slice of a file a range instance may be provided and will have improved performance over other sequence types like lists.</p> <code>None</code> <code>chunksize</code> <code>int</code> <p>The number of data lines to read for each yield. Lower values consume less memory. The default is 200,000 rows.</p> <code>int(200000.0)</code> <code>skip_empty</code> <code>bool</code> <p>A boolean indicating if rows with no values between the delimiters should be skipped. Default is True.</p> <code>True</code> <code>raise_ragged</code> <code>bool</code> <p>Boolean indicating if a row with more or fewer columns than expected should raise an error and stop reading. The default is False. Rows with fewer columns than the header will have None as  the fill value. Rows with more columns than the header will have None keys.</p> <code>False</code> <p>Yields:</p> Type Description <code>list[dict[str, CellType]]</code> <p>Chunksize number of dictionary rows with header names as keys.</p> Source code in <code>src/tabbed/reading.py</code> <pre><code>def read(\n    self,\n    start: int | None = None,\n    skips: Sequence[int] | None = None,\n    indices: Sequence | None = None,\n    chunksize: int = int(2e5),\n    skip_empty: bool = True,\n    raise_ragged: bool = False,\n) -&gt; Iterator[list[dict[str, CellType]]]:\n    \"\"\"Iteratively read dictionary rows that satisfy this Reader's tabs.\n\n    Args:\n        start:\n            A line number from the start of the file to begin reading data\n            from. If None and this reader's header has a line number, the\n            line following the header is the start. If None and the header\n            line number is None, the line following the last line in the\n            metadata is the start. If None and there is no header or\n            metadata, the start line is 0.\n        skips:\n            A sequence of line numbers to skip during reading.\n        indices:\n            A sequence of line numbers to read rows from. If None. all rows\n            from start not in skips will be read. If attempting to read\n            a slice of a file a range instance may be provided and will have\n            improved performance over other sequence types like lists.\n        chunksize:\n            The number of data lines to read for each yield. Lower values\n            consume less memory. The default is 200,000 rows.\n        skip_empty:\n            A boolean indicating if rows with no values between the\n            delimiters should be skipped. Default is True.\n        raise_ragged:\n            Boolean indicating if a row with more or fewer columns than\n            expected should raise an error and stop reading. The default is\n            False. Rows with fewer columns than the header will have None\n            as  the fill value. Rows with more columns than the header will\n            have None keys.\n\n    Yields:\n        Chunksize number of dictionary rows with header names as keys.\n\n    Raises:\n        A csv.Error is issued if a ragged row is encountered and\n        raise_ragged is True. Casting problems do not raise errors but\n        gracefully return strings when encountered.\n\n        A ValueError is issued if start and indices are provided and the\n        first indexed line to read in indices is less than the line to start\n        reading from.\n    \"\"\"\n\n    skips = [] if not skips else skips\n\n    # poll types &amp; formats, inconsistencies will trigger casting error log\n    types, _ = self._sniffer.types(self.poll, self.exclude)\n    formats, _ = self._sniffer.datetime_formats(self.poll, self.exclude)\n    castings = dict(zip(self.header.names, zip(types, formats)))\n\n    # initialize casting and ragged row errors\n    self.errors.casting = []\n    self.errors.ragged = []\n\n    # construct a row iterator\n    row_iter, row_start = self._prime(start, indices)\n\n    fifo: deque[dict[str, CellType]] = deque()\n    for line, dic in enumerate(row_iter, row_start):\n\n        if line in skips:\n            continue\n\n        if indices and line not in indices:\n            continue\n\n        if not any(dic.values()) and skip_empty:\n            continue\n\n        # chk &amp; log raggedness\n        dic = self._log_ragged(line, dic, raise_ragged)\n\n        # perform casts, log errors &amp; filter with tabulator\n        arow = {}\n        for name, astr in dic.items():\n\n            casting, fmt = castings[name]\n            try:\n                arow[name] = parsing.convert(\n                    astr, self.decimal, casting, fmt\n                )\n            except (ValueError, OverflowError, TypeError):\n                # on exception leave astr unconverted &amp; log casting error\n                msg = f\"line = {line}, column = '{name}'\"\n                self.errors.casting.append(msg)\n                arow[name] = astr\n\n        # apply tabs to filter row\n        row = self.tabulator(arow)\n\n        if row:\n            fifo.append(row)\n\n        if len(fifo) &gt;= chunksize:\n            yield [fifo.popleft() for _ in range(chunksize)]\n\n    yield list(fifo)\n    self.infile.seek(0)\n</code></pre>"},{"location":"reference/reading/#tabbed.reading.Reader.peek","title":"<code>peek(count=10)</code>","text":"<p>Prints count number of lines from the first line of the file.</p> <p>This method can be used to ensure this Reader identifies the correct metadata, header and data start locations.</p> <p>Parameters:</p> Name Type Description Default <code>count</code> <code>int</code> <p>The number of lines to print.</p> <code>10</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/tabbed/reading.py</code> <pre><code>def peek(self, count: int = 10) -&gt; None:\n    \"\"\"Prints count number of lines from the first line of the file.\n\n    This method can be used to ensure this Reader identifies the correct\n    metadata, header and data start locations.\n\n    Args:\n        count:\n            The number of lines to print.\n\n    Returns:\n        None\n    \"\"\"\n\n    cnt = 0\n    while cnt &lt; count:\n        CRED = '\\033[91m'\n        CEND = '\\033[0m'\n        print(CRED + f'{cnt}' + CEND, next(self.infile).rstrip())\n        cnt += 1\n\n    self.infile.seek(0)\n</code></pre>"},{"location":"reference/reading/#tabbed.reading.Reader.close","title":"<code>close()</code>","text":"<p>Closes this Reader's infile resource.</p> Source code in <code>src/tabbed/reading.py</code> <pre><code>def close(self):\n    \"\"\"Closes this Reader's infile resource.\"\"\"\n\n    self.infile.close()\n</code></pre>"},{"location":"reference/reference/","title":"Reference","text":"<p>Tabbed consist of 4 components that work together to read a delimited text file. The <code>reading</code>,<code>sniffing</code>,<code>tabbing</code>, and <code>parsing</code> modules contain these components. A Reader instance from the `reading' module can modify and call all of these components, making the reader the main interface for users.  Developers and curious users looking for Tabbed's source code documentation can find it here.</p>"},{"location":"reference/reference/#reading","title":"reading","text":""},{"location":"reference/reference/#sniffing","title":"sniffing","text":""},{"location":"reference/reference/#tabbing","title":"tabbing","text":""},{"location":"reference/reference/#parsing","title":"parsing","text":""},{"location":"reference/sniffing/","title":"Sniffing","text":""},{"location":"reference/sniffing/#tabbed.sniffing","title":"<code>tabbed.sniffing</code>","text":"<p>Tools for determining the dialect and structure of a csv file that may contain metadata, a header, and a data section.</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer","title":"<code>tabbed.sniffing.Sniffer</code>","text":"<p>               Bases: <code>ReprMixin</code></p> <p>A tool for inferring the dialect and structure of a CSV file.</p> <p>The formatting of CSV files can vary widely. Python's builtin Sniffer is capable of handling different dialects (separators, line terminators, quotes etc) but assumes the first line within the file is a header or a row of unheaded data. In practice, many CSV files contain metadata prior to the header or data section. While these files are not compliant with CSV standards (RFC-4180), their broad use necessitates file sniffing that infers both dialect and structure. To date, some csv readers such as Pandas read_csv allow metadata rows to be skipped but no formal mechanism for sniffing dialect, metadata and header information exist. This Sniffer supports these operations.</p> <p>Attributes:</p> Name Type Description <code>infile</code> <p>An open file, an IO instance.</p> <code>line_count</code> <p>The number of lines in infile.</p> <code>start</code> <code>int</code> <p>The start line of infile for collecting a sample of 'amount' number of lines.</p> <code>amount</code> <code>int</code> <p>The number of infile lines to sample for dialect, header and metadata detection. The initial value defaults to the smaller of line_count or 100 lines. The amount should be large enough to include some of the data section of the file.</p> <code>skips</code> <code>list[int]</code> <p>Line numbers to ignore during sample collection.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; delimiter = ';'\n&gt;&gt;&gt; # make a metadata and add to text that will be written to tempfile\n&gt;&gt;&gt; metadata = {'exp': '3', 'name': 'Paul Dirac', 'date': '11/09/1942'}\n&gt;&gt;&gt; text = [delimiter.join([key, val]) for key, val in metadata.items()]\n&gt;&gt;&gt; # make a header and row to skip and add to text\n&gt;&gt;&gt; header = delimiter.join('group count color'.split())\n&gt;&gt;&gt; to_skip = delimiter.join('please ignore this line'.split())\n&gt;&gt;&gt; text.extend([header, to_skip])\n&gt;&gt;&gt; # make some data rows and add to text\n&gt;&gt;&gt; group = 'a c b b c a c b c a a c'.split()\n&gt;&gt;&gt; count = '22 2 13 15 4 19 4 21 5 24 18 1'.split()\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; data = [delimiter.join(row) for row in zip(group, count, color)]\n&gt;&gt;&gt; text.extend(data)\n&gt;&gt;&gt; # create a temp file and dump our text\n&gt;&gt;&gt; outfile = tempfile.TemporaryFile(mode='w+')\n&gt;&gt;&gt; _ = outfile.write('\\n'.join(text))\n&gt;&gt;&gt; # create a sniffer\n&gt;&gt;&gt; sniffer = Sniffer(outfile)\n&gt;&gt;&gt; # change the sample amount to 10 lines and skip line 4\n&gt;&gt;&gt; # you would know to do this by inspecting the sample property\n&gt;&gt;&gt; # and seeing the problematic line 4\n&gt;&gt;&gt; sniffer.amount = 10\n&gt;&gt;&gt; sniffer.skips = [4]\n&gt;&gt;&gt; sniffer.sniff()\n&gt;&gt;&gt; print(sniffer.dialect)\nSimpleDialect(';', '\"', None)\n&gt;&gt;&gt; # ask the sniffer to return a Header\n&gt;&gt;&gt; header = sniffer.header(poll=4)\n&gt;&gt;&gt; print(header)\n...\nHeader(line=3,\nnames=['group', 'count', 'color'],\nstring='group;count;color')\n&gt;&gt;&gt; # ask sniffer for the metadata given the header\n&gt;&gt;&gt; sniffer.metadata(header)\n...\nMetaData(lines=(0, 3),\nstring='exp;3\\nname;Paul Dirac\\ndate;11/09/1942')\n&gt;&gt;&gt; # ask for the column types and consistency of types\n&gt;&gt;&gt; # by polling the last 4 rows\n&gt;&gt;&gt; types, consistent = sniffer.types(poll=4)\n&gt;&gt;&gt; print(types)\n[&lt;class 'str'&gt;, &lt;class 'int'&gt;, &lt;class 'str'&gt;]\n&gt;&gt;&gt; print(consistent)\nTrue\n&gt;&gt;&gt; # close the temp outfile resource\n&gt;&gt;&gt; outfile.close()\n</code></pre> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>class Sniffer(ReprMixin):\n    r\"\"\"A tool for inferring the dialect and structure of a CSV file.\n\n    The formatting of CSV files can vary widely. Python's builtin Sniffer is\n    capable of handling different dialects (separators, line terminators, quotes\n    etc) but assumes the first line within the file is a header or a row of\n    unheaded data. In practice, many CSV files contain metadata prior to the\n    header or data section. While these files are not compliant with CSV\n    standards (RFC-4180), their broad use necessitates file sniffing that infers\n    both dialect and structure. To date, some csv readers such as Pandas\n    read_csv allow metadata rows to be skipped but no formal mechanism for\n    sniffing dialect, metadata and header information exist. This Sniffer\n    supports these operations.\n\n    Attributes:\n        infile:\n            An open file, an IO instance.\n        line_count:\n            The number of lines in infile.\n        start:\n            The start line of infile for collecting a sample of 'amount' number\n            of lines.\n        amount:\n            The number of infile lines to sample for dialect, header and\n            metadata detection. The initial value defaults to the smaller of\n            line_count or 100 lines. The amount should be large enough to\n            include some of the data section of the file.\n        skips:\n            Line numbers to ignore during sample collection.\n\n    Examples:\n        &gt;&gt;&gt; import tempfile\n        &gt;&gt;&gt; delimiter = ';'\n        &gt;&gt;&gt; # make a metadata and add to text that will be written to tempfile\n        &gt;&gt;&gt; metadata = {'exp': '3', 'name': 'Paul Dirac', 'date': '11/09/1942'}\n        &gt;&gt;&gt; text = [delimiter.join([key, val]) for key, val in metadata.items()]\n        &gt;&gt;&gt; # make a header and row to skip and add to text\n        &gt;&gt;&gt; header = delimiter.join('group count color'.split())\n        &gt;&gt;&gt; to_skip = delimiter.join('please ignore this line'.split())\n        &gt;&gt;&gt; text.extend([header, to_skip])\n        &gt;&gt;&gt; # make some data rows and add to text\n        &gt;&gt;&gt; group = 'a c b b c a c b c a a c'.split()\n        &gt;&gt;&gt; count = '22 2 13 15 4 19 4 21 5 24 18 1'.split()\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; data = [delimiter.join(row) for row in zip(group, count, color)]\n        &gt;&gt;&gt; text.extend(data)\n        &gt;&gt;&gt; # create a temp file and dump our text\n        &gt;&gt;&gt; outfile = tempfile.TemporaryFile(mode='w+')\n        &gt;&gt;&gt; _ = outfile.write('\\n'.join(text))\n        &gt;&gt;&gt; # create a sniffer\n        &gt;&gt;&gt; sniffer = Sniffer(outfile)\n        &gt;&gt;&gt; # change the sample amount to 10 lines and skip line 4\n        &gt;&gt;&gt; # you would know to do this by inspecting the sample property\n        &gt;&gt;&gt; # and seeing the problematic line 4\n        &gt;&gt;&gt; sniffer.amount = 10\n        &gt;&gt;&gt; sniffer.skips = [4]\n        &gt;&gt;&gt; sniffer.sniff()\n        &gt;&gt;&gt; print(sniffer.dialect)\n        SimpleDialect(';', '\"', None)\n        &gt;&gt;&gt; # ask the sniffer to return a Header\n        &gt;&gt;&gt; header = sniffer.header(poll=4)\n        &gt;&gt;&gt; print(header)\n        ... #doctest: +NORMALIZE_WHITESPACE\n        Header(line=3,\n        names=['group', 'count', 'color'],\n        string='group;count;color')\n        &gt;&gt;&gt; # ask sniffer for the metadata given the header\n        &gt;&gt;&gt; sniffer.metadata(header)\n        ... #doctest: +NORMALIZE_WHITESPACE\n        MetaData(lines=(0, 3),\n        string='exp;3\\nname;Paul Dirac\\ndate;11/09/1942')\n        &gt;&gt;&gt; # ask for the column types and consistency of types\n        &gt;&gt;&gt; # by polling the last 4 rows\n        &gt;&gt;&gt; types, consistent = sniffer.types(poll=4)\n        &gt;&gt;&gt; print(types)\n        [&lt;class 'str'&gt;, &lt;class 'int'&gt;, &lt;class 'str'&gt;]\n        &gt;&gt;&gt; print(consistent)\n        True\n        &gt;&gt;&gt; # close the temp outfile resource\n        &gt;&gt;&gt; outfile.close()\n    \"\"\"\n\n    # help users set sane values for the sniffer\n    # pylint: disable-next=R0917, dangerous-default-value\n    def __init__(\n        self,\n        infile: IO[str],\n        start: int = 0,\n        amount: int = 100,\n        skips: list[int] | None = None,\n        delimiters: list[str] = [',', ';', '|', '\\t'],\n        decimal: str = '.',\n    ) -&gt; None:\n        \"\"\"Initialize this sniffer.\n\n        Args:\n            infile:\n                A I/O stream instance such as returned by open.\n            start:\n                The start line of infile for collecting a sample of lines.\n            amount:\n                The number of infile lines to sample for dialect detection and\n                locating header and metadata positions. The initial value defaults\n                to the smaller of the infiles length or 100 lines.\n            skips:\n                Line numbers to ignore during sample collection.\n            delimiters:\n                A restricted list of delimiter strings for improving dialect\n                detection. If None, any character will be considered a valid\n                delimiter.\n            decimal:\n                The format of the decimal notation. Defaults to '.'.\n\n        Raises:\n            SoptIteration: is raised if start is greater than infile's size.\n\n        Notes:\n            Sniffer deviates from Python's Sniffer in that infile is strictly an\n            IO stream, not a list because detecting the metadata and header\n            structures requires movement within the file via 'seek'.\n        \"\"\"\n\n        self.infile = infile\n        self.infile.seek(0)\n        self._start = start\n        self._amount = amount\n        self._skips = skips if skips else []\n        # remove decimal from delimiter consideration\n        delims = [d for d in delimiters if d != decimal]\n        self.decimal = decimal\n        # get sample for infile and sniff\n        self._resample()\n        self.sniff(delims)\n\n    @property\n    def start(self) -&gt; int:\n        \"\"\"Returns the start line of this Sniffer's sample.\"\"\"\n\n        return self._start\n\n    @start.setter\n    def start(self, value: int) -&gt; None:\n        \"\"\"Sets the start line &amp; updates this Sniffer's sample\n\n        Args:\n            value:\n                A new sample start line.\n        \"\"\"\n\n        self._start = value\n        self._resample()\n\n    @property\n    def amount(self) -&gt; int:\n        \"\"\"Returns the number of lines in Sniffer's sample.\"\"\"\n\n        return self._amount\n\n    @amount.setter\n    def amount(self, value: int) -&gt; None:\n        \"\"\"Sets the number of lines &amp; updates this Sniffer's sample.\n\n        Args:\n            value:\n                The new number of joined lines in the sample.\n        \"\"\"\n\n        self._amount = value\n        self._resample()\n\n    @property\n    def skips(self) -&gt; list[int]:\n        \"\"\"Returns the skipped lines excluded from this Sniffer's sample.\"\"\"\n\n        return self._skips\n\n    @skips.setter\n    def skips(self, other: list[int]) -&gt; None:\n        \"\"\"Sets the lines to exclude from this Sniffer's sample.\"\"\"\n\n        self._skips = other\n        self._resample()\n\n    @property\n    def sample(self) -&gt; str:\n        \"\"\"Returns this Sniffer's sample string.\"\"\"\n\n        return self._sample\n\n    @property\n    def lines(self) -&gt; list[int]:\n        \"\"\"Returns a list of integer line numbers comprising the sample.\"\"\"\n\n        return self._lines\n\n    @property\n    def dialect(self) -&gt; SimpleDialect | None:\n        \"\"\"Returns this Sniffer's dialect.\"\"\"\n\n        return self._dialect\n\n    @dialect.setter\n    def dialect(self, value: SimpleDialect | None) -&gt; None:\n        \"\"\"Sets this Sniffer's dialect.\n\n        Args:\n            dialect:\n                A clevercsv SimpleDialect instance containing a delimiter,\n                escape character and quote character.\n\n        Returns:\n            None\n        \"\"\"\n\n        if value:\n            # python 3.11 deprecated '' for delimiter, escape &amp; quotechars\n            delimiter = '\\r' if value.delimiter == '' else value.delimiter\n            escapechar = None if value.escapechar == '' else value.escapechar\n            quotechar = '\"' if not value.quotechar else value.quotechar\n            value.delimiter = delimiter\n            value.escapechar = escapechar\n            value.quotechar = quotechar\n\n        self._dialect = value\n\n    @property\n    def rows(self) -&gt; list[list[str]]:\n        \"\"\"Returns list of sample rows from this Sniffer's sample string.\n\n        This method splits the sample string on new line chars, strips white\n        spaces and replaces all double-quotes with single quotes.\n\n        Returns:\n            A list of list of strings from the sample string\n        \"\"\"\n\n        if self.dialect is None:\n            msg = \"Dialect is unknown, please call sniff method or set dialect.\"\n            raise TypeError(msg)\n\n        result = []\n        delimiter = self.dialect.delimiter\n\n        # single column data uses carriage return delimiter\n        if delimiter == '\\r':\n            return [\n                [astr.replace('\"', '')] for astr in self.sample.splitlines()\n            ]\n\n        # split sample_str on terminators, strip &amp; split each line on delimiter\n        for line in self.sample.splitlines():\n            # lines may end in delimiter leading to empty trailing cells\n            stripped = line.rstrip(delimiter)\n            row = stripped.split(self.dialect.delimiter)\n            # remove any double quotes\n            row = [astring.replace('\"', '') for astring in row]\n            result.append(row)\n\n        return result\n\n    def _move(self, line: int) -&gt; None:\n        \"\"\"Moves the line pointer in this file to line number.\n\n        Args:\n            line:\n                A line number to move to within this Sniffer's infile.\n\n        Returns:\n            None but advances the line pointer to line.\n\n        Raises:\n            A StopIteration is issued if line is greater than Sniffer's infile\n            size.\n        \"\"\"\n\n        self.infile.seek(0)\n        for _ in range(line):\n            next(self.infile)\n\n    def _resample(self) -&gt; None:\n        \"\"\"Sample from infile using the start, amount and skip properties.\"\"\"\n\n        self._move(self.start)\n        result = SimpleNamespace(indices=[], linestrs=[])\n        amount = self.amount + len(self.skips)\n        for current in range(self.start, amount + self.start):\n\n            line = self.infile.readline()\n            # only store non-blank lines\n            if current not in self.skips and line:\n                result.linestrs.append(line)\n                result.indices.append(current)\n\n        # move line pointer back to start of the file\n        self._move(0)\n        sampled = ''.join(result.linestrs)\n        self._sample: str = sampled\n        self._lines: list[int] = result.indices\n\n    def sniff(self, delimiters: list[str] | None = None) -&gt; None:\n        \"\"\"Returns a clevercsv SimpleDialect from this instances sample.\n\n        Dialect is detected using clevercsv's sniffer as it has shown improved\n        dialect detection accuracy over Python's csv sniffer built-in.\n\n        Args:\n            delimiters:\n                A string of possibly valid delimiters see csv.Sniffer.sniff.\n\n        Returns:\n            A SimpleDialect instance (see clevercsv.dialect) or None if sniffing\n            is inconclusive.\n\n        References:\n            van den Burg, G.J.J., Naz\u00e1bal, A. &amp; Sutton, C. Wrangling messy CSV\n            files by detecting row and type patterns. Data Min Knowl Disc 33,\n            1799\u20131820 (2019). https://doi.org/10.1007/s10618-019-00646-y\n        \"\"\"\n\n        # result is None if clevercsv's sniff is indeterminant\n        result = clevercsv.Sniffer().detect(self.sample, delimiters=delimiters)\n        if result is None:\n            msg1 = \"Dialect could not be determined from Sniffer's sample.  \"\n            msg2 = \"Please set this Sniffer's dialect attribute.\"\n            warnings.warn(msg1 + msg2)\n            self._dialect = None\n        else:\n            self.dialect = result\n\n    # no mutation of exclude list here\n    # pylint: disable-next=dangerous-default-value\n    def types(\n        self,\n        poll: int,\n        exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n    ) -&gt; tuple[CellTypes, bool]:\n        \"\"\"Infer the column types from the last poll count rows.\n\n        Args:\n            poll:\n                The number of last sample rows to poll for type.\n            exclude:\n                A sequence of characters that indicate missing values. Rows\n                containing these strings will be ignored for type determination.\n\n        Returns:\n            A list of types and a boolean indicating if types are\n            consistent across polled rows. Ints, floats and complex within the\n            same column are defined as consistent.\n        \"\"\"\n\n        rows = self.rows[-poll:]\n        rows = [row for row in rows if not bool(set(exclude).intersection(row))]\n        if not rows:\n            msg = (\n                f'Types could not be determined as last {poll} polling '\n                f'rows all contained at least one exclusion {exclude}. Try '\n                'increasing the number of polling rows.'\n            )\n            raise RuntimeError(msg)\n\n        cols = list(zip(*rows))\n        type_cnts = [\n            Counter([type(parsing.convert(el, self.decimal)) for el in col])\n            for col in cols\n        ]\n\n        consistent = True\n        for s in [set(cnts) for cnts in type_cnts]:\n            # inconsistent if &gt; 1 type per column &amp; any non-numerics\n            if len(s) &gt; 1 and not s.issubset({float, int, complex}):\n                consistent = False\n                break\n\n        common_types = [cnt.most_common(1)[0][0] for cnt in type_cnts]\n\n        return common_types, consistent\n\n    # no mutation of exclude list here\n    # pylint: disable-next=dangerous-default-value\n    def datetime_formats(\n        self,\n        poll: int,\n        exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n    ) -&gt; tuple[list[str | None], bool]:\n        \"\"\"Infer time, date or datetime formats from last poll count rows.\n\n        Args:\n            poll:\n                The number of last sample rows to poll for type and format\n                consistency.\n\n        Returns:\n            A tuple containing a list of formats the same length as last polled\n            row and a boolean indicating if the formats are consistent across\n            the polled rows. Columns that are not time, date or datetime type\n            have a format of None.\n        \"\"\"\n\n        fmts = {\n            time: parsing.time_formats(),\n            date: parsing.date_formats(),\n            datetime: parsing.datetime_formats(),\n        }\n        polled = []\n        for row in self.rows[-poll:]:\n            row_fmts = []\n            for astring, tp in zip(row, self.types(poll, exclude)[0]):\n                fmt = (\n                    parsing.find_format(astring, fmts[tp])\n                    if tp in fmts\n                    else None\n                )\n                row_fmts.append(fmt)\n            polled.append(row_fmts)\n\n        # consistency within each column of polled\n        consistent = all(len(set(col)) == 1 for col in list(zip(*polled)))\n\n        return polled[-1], consistent\n\n    def _length_diff(\n        self,\n        poll: int,\n        exclude: list[str],\n    ) -&gt; tuple[int | None, list[str] | None]:\n        \"\"\"Locates metadata by identifying the first row from the end of the\n        sample whose length does not match the length of the last poll rows.\n\n        This method assumes that the metadata row lengths do not match the data\n        row lengths. This can obviously be untrue but detecting the difference\n        between a header row whose length must match the number of data columns\n        from a metadata row with the same number of columns is challenging.\n\n        Args:\n            poll:\n                The number of last sample rows to poll for common types.\n            exclude:\n                A sequence of characters that indicate missing values. Rows\n                containing these strings will be ignored.\n\n        Returns:\n            A 2-tuple of integer line number and the metadata row if found and\n            a 2-tuple of Nones otherwise.\n        \"\"\"\n\n        types, _ = self.types(poll, exclude)\n        for idx, row in reversed(list(zip(self.lines, self.rows))):\n\n            if len(row) != len(types):\n                return idx, row\n\n        return None, None\n\n    def _type_diff(\n        self,\n        poll: int,\n        exclude: list[str],\n    ) -&gt; tuple[int | None, list[str] | None]:\n        \"\"\"Locates a header row by looking for the first row from the last of\n        this Sniffer's rows whose types do not match the last polled row types.\n\n        This heuristic assumes a consistent type within a column of data. If\n        this is found to be untrue it returns a two-tuple of Nones. Ints, floats\n        and complex are treated as consistent by type_diff.\n\n        Args:\n            poll:\n                The number of last sample rows to poll for common types.\n            exclude:\n                A sequence of characters that indicate missing values. Rows\n                containing these strings will be ignored.\n\n        Returns:\n            A 2-tuple integer line number and header row or a 2-tuple of Nones.\n        \"\"\"\n\n        types, consistent = self.types(poll, exclude)\n\n        if not consistent:\n            msg = 'Detection failure due to inconsistent column data types'\n            warnings.warn(msg)\n            return None, None\n\n        # int, float and complex mismatches are not type mismatches\n        numerics = {int, float, complex}\n        for idx, row in reversed(list(zip(self.lines, self.rows))):\n\n            # ignore blank rows\n            if set(row) == {''}:\n                continue\n\n            # ignore rows that have missing values\n            if bool(set(exclude).intersection(row)):\n                continue\n\n            if len(row) != len(types):\n                # we've encountered a metadata row without hitting a header\n                return None, None\n\n            row_types = [type(parsing.convert(el, self.decimal)) for el in row]\n            # check types\n            for typ, expect in zip(row_types, types):\n                if typ != expect and not {typ, expect}.issubset(numerics):\n                    return idx, row\n\n        return None, None\n\n    def _string_diff(\n        self,\n        poll: int,\n        exclude: list[str],\n        len_requirement: bool = True,\n    ) -&gt; tuple[int | None, list[str] | None]:\n        \"\"\"Locates first row from last whose strings have no overlap with\n        strings in the last poll rows.\n\n        Args:\n            poll:\n                The number of last sample rows to poll for string values.\n\n            exclude:\n                A sequence of characters that indicate missing values. Rows\n                containing these strings will be ignored.\n            len_requirement:\n                A boolean indicating if the first row from last with a type\n                mismatch must have the same length as the last row of the\n                sample. This will be True for headers and False for metadata.\n\n        Returns:\n            An integer line number and header row or a 2-tuple of Nones\n        \"\"\"\n\n        observed = set(chain.from_iterable(self.rows[-poll:]))\n        for idx, row in reversed(list(zip(self.lines, self.rows))):\n\n            items = set(row)\n            # ignore rows with missing values\n            if bool(set(exclude).intersection(items)):\n                continue\n\n            # check disjoint with observed and completeness\n            disjoint = items.isdisjoint(observed)\n            complete = len(row) == len(self.rows[-1])\n\n            if not len_requirement:\n                # complete is always True if no length requirement\n                complete = True\n\n            if disjoint and complete:\n                return idx, row\n\n            # add unseen items to observed\n            observed.update(items)\n\n        return None, None\n\n    # no mutation of exclude list here\n    # pylint: disable-next=dangerous-default-value\n    def header(\n        self,\n        poll: int,\n        exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n    ) -&gt; Header:\n        \"\"\"Detects the header row (if any) from this Sniffers sample rows.\n\n        Headers are located using one of two possible methods.\n            1. If the last row contains mixed types and the last poll rows have\n               consistent types, then the first row from the last whose types\n               differ from the last row types and whose length matches the last\n               row is taken as the header.\n            2. If the last poll rows are all string type. The first row from the\n               last with string values that have never been seen in the previous\n               rows and whose length matches the last row is taken to be the\n               header. Caution, the poll amount should be sufficiently large\n               enough to sample the possible string values expected in the data\n               section. If the header is not correct, consider increasing the\n               poll rows parameter.\n\n        Args:\n            poll:\n                The number of last sample rows to poll for locating the header\n                using string or type differences. Poll should be large enough to\n                capture many of the string values that appear in the data\n                section.\n            exclude:\n                A sequence of characters that indicate missing values. Rows\n                containing these strings will be ignored.\n\n        Notes:\n            If no header is detected this method constructs a header. The names\n            in this header are of the form; 'Column_1', ... 'Column_n' where\n            n is the expected number of columns from the last row of the sample\n            rows.  Just like all other file sniffers, this heuristic will make\n            mistakes.  A judicious sample choice that ignores problematic rows\n            via the skip parameter may aide detection.\n\n        Returns:\n            A Header dataclass instance.\n        \"\"\"\n\n        types, _ = self.types(poll, exclude)\n        if all(typ == str for typ in types):\n            line, row = self._string_diff(poll, exclude)\n\n        else:\n            line, row = self._type_diff(poll, exclude)\n\n        if line is None:\n            row = [f'Column_{i}' for i in range(len(self.rows[-1]))]\n\n        # type-narrow for mypy check-- row can no longer be None\n        assert isinstance(row, list)\n        # get original string if line\n        if line is not None:\n            # string should include the rows we skipped so use sample not rows\n            s = self.sample.splitlines()[self.lines.index(line)]\n        else:\n            s = None\n\n        return Header(line=line, names=row, string=s)\n\n    # no mutation of exclude list here\n    # pylint: disable-next=dangerous-default-value\n    def metadata(\n        self,\n        header: Header | None,\n        poll: int | None = None,\n        exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n    ) -&gt; MetaData:\n        \"\"\"Detects the metadata section (if any) in this Sniffer's sample.\n\n        Args:\n            header:\n                A Header dataclass instance.\n            poll:\n                The number of last sample rows to poll for locating metadata by\n                length differences if the header arg is None.\n            exclude:\n                A sequence of characters that indicate missing values. Rows\n                containing these strings will be ignored during metadata\n                detection. This is ignored if a header is given.\n\n        Returns:\n            A MetaData dataclass instance.\n        \"\"\"\n\n        # if header provided get lines upto header line\n        if header and header.line:\n            idx = self.lines.index(header.line)\n            s = '\\n'.join(self.sample.splitlines()[0:idx])\n            return MetaData((0, header.line), s)\n\n        if not header and poll is None:\n            msg = 'Arguments header and poll cannot both be None type'\n            raise ValueError(msg)\n\n        # type narrow poll to int type for mypy\n        assert isinstance(poll, int)\n        line, _ = self._length_diff(poll, exclude)\n        if line is not None:\n            metarows = self.sample.splitlines()[: line + 1]\n            string = '\\n'.join(metarows)\n            return MetaData((0, line + 1), string)\n\n        return MetaData((0, None), None)\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.start","title":"<code>start</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the start line of this Sniffer's sample.</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.amount","title":"<code>amount</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the number of lines in Sniffer's sample.</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.skips","title":"<code>skips</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the skipped lines excluded from this Sniffer's sample.</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.lines","title":"<code>lines</code>  <code>property</code>","text":"<p>Returns a list of integer line numbers comprising the sample.</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.dialect","title":"<code>dialect</code>  <code>property</code> <code>writable</code>","text":"<p>Returns this Sniffer's dialect.</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.rows","title":"<code>rows</code>  <code>property</code>","text":"<p>Returns list of sample rows from this Sniffer's sample string.</p> <p>This method splits the sample string on new line chars, strips white spaces and replaces all double-quotes with single quotes.</p> <p>Returns:</p> Type Description <code>list[list[str]]</code> <p>A list of list of strings from the sample string</p>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.__init__","title":"<code>__init__(infile, start=0, amount=100, skips=None, delimiters=[',', ';', '|', '\\t'], decimal='.')</code>","text":"<p>Initialize this sniffer.</p> <p>Parameters:</p> Name Type Description Default <code>infile</code> <code>IO[str]</code> <p>A I/O stream instance such as returned by open.</p> required <code>start</code> <code>int</code> <p>The start line of infile for collecting a sample of lines.</p> <code>0</code> <code>amount</code> <code>int</code> <p>The number of infile lines to sample for dialect detection and locating header and metadata positions. The initial value defaults to the smaller of the infiles length or 100 lines.</p> <code>100</code> <code>skips</code> <code>list[int] | None</code> <p>Line numbers to ignore during sample collection.</p> <code>None</code> <code>delimiters</code> <code>list[str]</code> <p>A restricted list of delimiter strings for improving dialect detection. If None, any character will be considered a valid delimiter.</p> <code>[',', ';', '|', '\\t']</code> <code>decimal</code> <code>str</code> <p>The format of the decimal notation. Defaults to '.'.</p> <code>'.'</code> <p>Raises:</p> Type Description <code>SoptIteration</code> <p>is raised if start is greater than infile's size.</p> Notes <p>Sniffer deviates from Python's Sniffer in that infile is strictly an IO stream, not a list because detecting the metadata and header structures requires movement within the file via 'seek'.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def __init__(\n    self,\n    infile: IO[str],\n    start: int = 0,\n    amount: int = 100,\n    skips: list[int] | None = None,\n    delimiters: list[str] = [',', ';', '|', '\\t'],\n    decimal: str = '.',\n) -&gt; None:\n    \"\"\"Initialize this sniffer.\n\n    Args:\n        infile:\n            A I/O stream instance such as returned by open.\n        start:\n            The start line of infile for collecting a sample of lines.\n        amount:\n            The number of infile lines to sample for dialect detection and\n            locating header and metadata positions. The initial value defaults\n            to the smaller of the infiles length or 100 lines.\n        skips:\n            Line numbers to ignore during sample collection.\n        delimiters:\n            A restricted list of delimiter strings for improving dialect\n            detection. If None, any character will be considered a valid\n            delimiter.\n        decimal:\n            The format of the decimal notation. Defaults to '.'.\n\n    Raises:\n        SoptIteration: is raised if start is greater than infile's size.\n\n    Notes:\n        Sniffer deviates from Python's Sniffer in that infile is strictly an\n        IO stream, not a list because detecting the metadata and header\n        structures requires movement within the file via 'seek'.\n    \"\"\"\n\n    self.infile = infile\n    self.infile.seek(0)\n    self._start = start\n    self._amount = amount\n    self._skips = skips if skips else []\n    # remove decimal from delimiter consideration\n    delims = [d for d in delimiters if d != decimal]\n    self.decimal = decimal\n    # get sample for infile and sniff\n    self._resample()\n    self.sniff(delims)\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.sniff","title":"<code>sniff(delimiters=None)</code>","text":"<p>Returns a clevercsv SimpleDialect from this instances sample.</p> <p>Dialect is detected using clevercsv's sniffer as it has shown improved dialect detection accuracy over Python's csv sniffer built-in.</p> <p>Parameters:</p> Name Type Description Default <code>delimiters</code> <code>list[str] | None</code> <p>A string of possibly valid delimiters see csv.Sniffer.sniff.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A SimpleDialect instance (see clevercsv.dialect) or None if sniffing</p> <code>None</code> <p>is inconclusive.</p> References <p>van den Burg, G.J.J., Naz\u00e1bal, A. &amp; Sutton, C. Wrangling messy CSV files by detecting row and type patterns. Data Min Knowl Disc 33, 1799\u20131820 (2019). https://doi.org/10.1007/s10618-019-00646-y</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def sniff(self, delimiters: list[str] | None = None) -&gt; None:\n    \"\"\"Returns a clevercsv SimpleDialect from this instances sample.\n\n    Dialect is detected using clevercsv's sniffer as it has shown improved\n    dialect detection accuracy over Python's csv sniffer built-in.\n\n    Args:\n        delimiters:\n            A string of possibly valid delimiters see csv.Sniffer.sniff.\n\n    Returns:\n        A SimpleDialect instance (see clevercsv.dialect) or None if sniffing\n        is inconclusive.\n\n    References:\n        van den Burg, G.J.J., Naz\u00e1bal, A. &amp; Sutton, C. Wrangling messy CSV\n        files by detecting row and type patterns. Data Min Knowl Disc 33,\n        1799\u20131820 (2019). https://doi.org/10.1007/s10618-019-00646-y\n    \"\"\"\n\n    # result is None if clevercsv's sniff is indeterminant\n    result = clevercsv.Sniffer().detect(self.sample, delimiters=delimiters)\n    if result is None:\n        msg1 = \"Dialect could not be determined from Sniffer's sample.  \"\n        msg2 = \"Please set this Sniffer's dialect attribute.\"\n        warnings.warn(msg1 + msg2)\n        self._dialect = None\n    else:\n        self.dialect = result\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.types","title":"<code>types(poll, exclude=['', ' ', '-', 'nan', 'NaN', 'NAN'])</code>","text":"<p>Infer the column types from the last poll count rows.</p> <p>Parameters:</p> Name Type Description Default <code>poll</code> <code>int</code> <p>The number of last sample rows to poll for type.</p> required <code>exclude</code> <code>list[str]</code> <p>A sequence of characters that indicate missing values. Rows containing these strings will be ignored for type determination.</p> <code>['', ' ', '-', 'nan', 'NaN', 'NAN']</code> <p>Returns:</p> Type Description <code>CellTypes</code> <p>A list of types and a boolean indicating if types are</p> <code>bool</code> <p>consistent across polled rows. Ints, floats and complex within the</p> <code>tuple[CellTypes, bool]</code> <p>same column are defined as consistent.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def types(\n    self,\n    poll: int,\n    exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n) -&gt; tuple[CellTypes, bool]:\n    \"\"\"Infer the column types from the last poll count rows.\n\n    Args:\n        poll:\n            The number of last sample rows to poll for type.\n        exclude:\n            A sequence of characters that indicate missing values. Rows\n            containing these strings will be ignored for type determination.\n\n    Returns:\n        A list of types and a boolean indicating if types are\n        consistent across polled rows. Ints, floats and complex within the\n        same column are defined as consistent.\n    \"\"\"\n\n    rows = self.rows[-poll:]\n    rows = [row for row in rows if not bool(set(exclude).intersection(row))]\n    if not rows:\n        msg = (\n            f'Types could not be determined as last {poll} polling '\n            f'rows all contained at least one exclusion {exclude}. Try '\n            'increasing the number of polling rows.'\n        )\n        raise RuntimeError(msg)\n\n    cols = list(zip(*rows))\n    type_cnts = [\n        Counter([type(parsing.convert(el, self.decimal)) for el in col])\n        for col in cols\n    ]\n\n    consistent = True\n    for s in [set(cnts) for cnts in type_cnts]:\n        # inconsistent if &gt; 1 type per column &amp; any non-numerics\n        if len(s) &gt; 1 and not s.issubset({float, int, complex}):\n            consistent = False\n            break\n\n    common_types = [cnt.most_common(1)[0][0] for cnt in type_cnts]\n\n    return common_types, consistent\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.datetime_formats","title":"<code>datetime_formats(poll, exclude=['', ' ', '-', 'nan', 'NaN', 'NAN'])</code>","text":"<p>Infer time, date or datetime formats from last poll count rows.</p> <p>Parameters:</p> Name Type Description Default <code>poll</code> <code>int</code> <p>The number of last sample rows to poll for type and format consistency.</p> required <p>Returns:</p> Type Description <code>list[str | None]</code> <p>A tuple containing a list of formats the same length as last polled</p> <code>bool</code> <p>row and a boolean indicating if the formats are consistent across</p> <code>tuple[list[str | None], bool]</code> <p>the polled rows. Columns that are not time, date or datetime type</p> <code>tuple[list[str | None], bool]</code> <p>have a format of None.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def datetime_formats(\n    self,\n    poll: int,\n    exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n) -&gt; tuple[list[str | None], bool]:\n    \"\"\"Infer time, date or datetime formats from last poll count rows.\n\n    Args:\n        poll:\n            The number of last sample rows to poll for type and format\n            consistency.\n\n    Returns:\n        A tuple containing a list of formats the same length as last polled\n        row and a boolean indicating if the formats are consistent across\n        the polled rows. Columns that are not time, date or datetime type\n        have a format of None.\n    \"\"\"\n\n    fmts = {\n        time: parsing.time_formats(),\n        date: parsing.date_formats(),\n        datetime: parsing.datetime_formats(),\n    }\n    polled = []\n    for row in self.rows[-poll:]:\n        row_fmts = []\n        for astring, tp in zip(row, self.types(poll, exclude)[0]):\n            fmt = (\n                parsing.find_format(astring, fmts[tp])\n                if tp in fmts\n                else None\n            )\n            row_fmts.append(fmt)\n        polled.append(row_fmts)\n\n    # consistency within each column of polled\n    consistent = all(len(set(col)) == 1 for col in list(zip(*polled)))\n\n    return polled[-1], consistent\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.header","title":"<code>header(poll, exclude=['', ' ', '-', 'nan', 'NaN', 'NAN'])</code>","text":"<p>Detects the header row (if any) from this Sniffers sample rows.</p> <p>Headers are located using one of two possible methods.     1. If the last row contains mixed types and the last poll rows have        consistent types, then the first row from the last whose types        differ from the last row types and whose length matches the last        row is taken as the header.     2. If the last poll rows are all string type. The first row from the        last with string values that have never been seen in the previous        rows and whose length matches the last row is taken to be the        header. Caution, the poll amount should be sufficiently large        enough to sample the possible string values expected in the data        section. If the header is not correct, consider increasing the        poll rows parameter.</p> <p>Parameters:</p> Name Type Description Default <code>poll</code> <code>int</code> <p>The number of last sample rows to poll for locating the header using string or type differences. Poll should be large enough to capture many of the string values that appear in the data section.</p> required <code>exclude</code> <code>list[str]</code> <p>A sequence of characters that indicate missing values. Rows containing these strings will be ignored.</p> <code>['', ' ', '-', 'nan', 'NaN', 'NAN']</code> Notes <p>If no header is detected this method constructs a header. The names in this header are of the form; 'Column_1', ... 'Column_n' where n is the expected number of columns from the last row of the sample rows.  Just like all other file sniffers, this heuristic will make mistakes.  A judicious sample choice that ignores problematic rows via the skip parameter may aide detection.</p> <p>Returns:</p> Type Description <code>Header</code> <p>A Header dataclass instance.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def header(\n    self,\n    poll: int,\n    exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n) -&gt; Header:\n    \"\"\"Detects the header row (if any) from this Sniffers sample rows.\n\n    Headers are located using one of two possible methods.\n        1. If the last row contains mixed types and the last poll rows have\n           consistent types, then the first row from the last whose types\n           differ from the last row types and whose length matches the last\n           row is taken as the header.\n        2. If the last poll rows are all string type. The first row from the\n           last with string values that have never been seen in the previous\n           rows and whose length matches the last row is taken to be the\n           header. Caution, the poll amount should be sufficiently large\n           enough to sample the possible string values expected in the data\n           section. If the header is not correct, consider increasing the\n           poll rows parameter.\n\n    Args:\n        poll:\n            The number of last sample rows to poll for locating the header\n            using string or type differences. Poll should be large enough to\n            capture many of the string values that appear in the data\n            section.\n        exclude:\n            A sequence of characters that indicate missing values. Rows\n            containing these strings will be ignored.\n\n    Notes:\n        If no header is detected this method constructs a header. The names\n        in this header are of the form; 'Column_1', ... 'Column_n' where\n        n is the expected number of columns from the last row of the sample\n        rows.  Just like all other file sniffers, this heuristic will make\n        mistakes.  A judicious sample choice that ignores problematic rows\n        via the skip parameter may aide detection.\n\n    Returns:\n        A Header dataclass instance.\n    \"\"\"\n\n    types, _ = self.types(poll, exclude)\n    if all(typ == str for typ in types):\n        line, row = self._string_diff(poll, exclude)\n\n    else:\n        line, row = self._type_diff(poll, exclude)\n\n    if line is None:\n        row = [f'Column_{i}' for i in range(len(self.rows[-1]))]\n\n    # type-narrow for mypy check-- row can no longer be None\n    assert isinstance(row, list)\n    # get original string if line\n    if line is not None:\n        # string should include the rows we skipped so use sample not rows\n        s = self.sample.splitlines()[self.lines.index(line)]\n    else:\n        s = None\n\n    return Header(line=line, names=row, string=s)\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Sniffer.metadata","title":"<code>metadata(header, poll=None, exclude=['', ' ', '-', 'nan', 'NaN', 'NAN'])</code>","text":"<p>Detects the metadata section (if any) in this Sniffer's sample.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>Header | None</code> <p>A Header dataclass instance.</p> required <code>poll</code> <code>int | None</code> <p>The number of last sample rows to poll for locating metadata by length differences if the header arg is None.</p> <code>None</code> <code>exclude</code> <code>list[str]</code> <p>A sequence of characters that indicate missing values. Rows containing these strings will be ignored during metadata detection. This is ignored if a header is given.</p> <code>['', ' ', '-', 'nan', 'NaN', 'NAN']</code> <p>Returns:</p> Type Description <code>MetaData</code> <p>A MetaData dataclass instance.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def metadata(\n    self,\n    header: Header | None,\n    poll: int | None = None,\n    exclude: list[str] = ['', ' ', '-', 'nan', 'NaN', 'NAN'],\n) -&gt; MetaData:\n    \"\"\"Detects the metadata section (if any) in this Sniffer's sample.\n\n    Args:\n        header:\n            A Header dataclass instance.\n        poll:\n            The number of last sample rows to poll for locating metadata by\n            length differences if the header arg is None.\n        exclude:\n            A sequence of characters that indicate missing values. Rows\n            containing these strings will be ignored during metadata\n            detection. This is ignored if a header is given.\n\n    Returns:\n        A MetaData dataclass instance.\n    \"\"\"\n\n    # if header provided get lines upto header line\n    if header and header.line:\n        idx = self.lines.index(header.line)\n        s = '\\n'.join(self.sample.splitlines()[0:idx])\n        return MetaData((0, header.line), s)\n\n    if not header and poll is None:\n        msg = 'Arguments header and poll cannot both be None type'\n        raise ValueError(msg)\n\n    # type narrow poll to int type for mypy\n    assert isinstance(poll, int)\n    line, _ = self._length_diff(poll, exclude)\n    if line is not None:\n        metarows = self.sample.splitlines()[: line + 1]\n        string = '\\n'.join(metarows)\n        return MetaData((0, line + 1), string)\n\n    return MetaData((0, None), None)\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Header","title":"<code>tabbed.sniffing.Header</code>  <code>dataclass</code>","text":"<p>An immutable dataclass representation of a text file's header.</p> <p>Attributes:</p> Name Type Description <code>line</code> <code>int | None</code> <p>The integer line number of this Header. If None, the header was not derived from a file.</p> <code>names</code> <code>list[str]</code> <p>The string names of each of the columns comprising the header. If these names contain spaces or repeat, this representation automatically amends them.</p> <code>string</code> <code>str | None</code> <p>The original string that was split to create header names.  If None, the names were not derived from a file.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>@dataclass(frozen=True)\nclass Header:\n    \"\"\"An immutable dataclass representation of a text file's header.\n\n    Attributes:\n        line:\n            The integer line number of this Header. If None, the header was not\n            derived from a file.\n        names:\n            The string names of each of the columns comprising the header. If\n            these names contain spaces or repeat, this representation\n            automatically amends them.\n        string:\n            The original string that was split to create header names.  If None,\n            the names were not derived from a file.\n    \"\"\"\n\n    line: int | None\n    names: list[str]\n    string: str | None\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Amend the names during initialization.\"\"\"\n\n        # relabel the names to replace spaces, repeats etc.\n        names = self._amend()\n        super().__setattr__('names', names)\n\n    def _amend(self):\n        \"\"\"Ensures header names have no spaces and are unique.\n\n        Header names may not have spaces. This function replaces spaces with\n        underscores. Header names must be unique. This function adds an\n        underscore plus an integer to names that repeat.\n        \"\"\"\n\n        # replace any blank chars with underscores\n        names = [name.strip().replace(' ', '_') for name in self.names]\n\n        # replace repeating names with name_i variants for i in [0, inf)\n        counted = Counter(names)\n        mapping = {\n            name: (\n                [name] if cnt &lt; 2 else [name + '_' + str(v) for v in range(cnt)]\n            )\n            for name, cnt in counted.items()\n        }\n\n        result = [mapping[name].pop(0) for name in names]\n        return result\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Header.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Amend the names during initialization.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Amend the names during initialization.\"\"\"\n\n    # relabel the names to replace spaces, repeats etc.\n    names = self._amend()\n    super().__setattr__('names', names)\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.Header._amend","title":"<code>_amend()</code>","text":"<p>Ensures header names have no spaces and are unique.</p> <p>Header names may not have spaces. This function replaces spaces with underscores. Header names must be unique. This function adds an underscore plus an integer to names that repeat.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>def _amend(self):\n    \"\"\"Ensures header names have no spaces and are unique.\n\n    Header names may not have spaces. This function replaces spaces with\n    underscores. Header names must be unique. This function adds an\n    underscore plus an integer to names that repeat.\n    \"\"\"\n\n    # replace any blank chars with underscores\n    names = [name.strip().replace(' ', '_') for name in self.names]\n\n    # replace repeating names with name_i variants for i in [0, inf)\n    counted = Counter(names)\n    mapping = {\n        name: (\n            [name] if cnt &lt; 2 else [name + '_' + str(v) for v in range(cnt)]\n        )\n        for name, cnt in counted.items()\n    }\n\n    result = [mapping[name].pop(0) for name in names]\n    return result\n</code></pre>"},{"location":"reference/sniffing/#tabbed.sniffing.MetaData","title":"<code>tabbed.sniffing.MetaData</code>  <code>dataclass</code>","text":"<p>An immutable dataclass representing a text file's metadata section.</p> <p>Attributes:</p> Name Type Description <code>lines</code> <code>tuple[int, int | None]</code> <p>A 2-tuple of start and stop of file lines containing metadata. If None, the file does not contain a metadata section.</p> <code>string</code> <code>str | None</code> <p>The string of metadata with no conversion read from file instance. If None, the file does not contain a metadata section.</p> Source code in <code>src/tabbed/sniffing.py</code> <pre><code>@dataclass(frozen=True)\nclass MetaData:\n    \"\"\"An immutable dataclass representing a text file's metadata section.\n\n    Attributes:\n        lines:\n            A 2-tuple of start and stop of file lines containing metadata. If\n            None, the file does not contain a metadata section.\n        string:\n            The string of metadata with no conversion read from file instance.\n            If None, the file does not contain a metadata section.\n    \"\"\"\n\n    lines: tuple[int, int | None]\n    string: str | None\n</code></pre>"},{"location":"reference/tabbing/","title":"Tabbing","text":""},{"location":"reference/tabbing/#tabbed.tabbing","title":"<code>tabbed.tabbing</code>","text":"<p>Tab instances are callables that return a boolean for a single row dictionary to indicate if the row should be accepted or rejected. This module has equality, membership, regular expression, rich comparison and custom callable Tabs. The Tabulator is the client facing interface for building Tab instances. It allows for Tab instances to be constructed from keyword arguments.</p>"},{"location":"reference/tabbing/#tabbed.tabbing.Tabulator","title":"<code>tabbed.tabbing.Tabulator</code>","text":"<p>               Bases: <code>ReprMixin</code></p> <p>A Callable for creating, storing &amp; applying Tabs to a row dictionary.</p> <p>Tablulators are the interface that should be used to create Tab instances. They allow Tabs to be constructed from keyword arguments and apply multiple Tabs sequentially to a row dictionary of file data. If columns from the file are provided, the Tabulator will restrict which columns of the row dictionary will be returned.</p> <p>Attributes:</p> Name Type Description <code>header</code> <p>A Header instance storing all column names of a file.</p> <code>tabs</code> <p>A list of tab instances to apply to each row.</p> <code>columns</code> <p>Columns to extract from each row as a list of column names, a list of integer column indices or a single re pattern to match column names against.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; names = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(names, values)) for values in items]\n&gt;&gt;&gt; #create a Header instance\n&gt;&gt;&gt; header = Header(line=0, names=names, string=''.join(names))\n&gt;&gt;&gt; # create a tabulator from keyword args defining tabs\n&gt;&gt;&gt; tabulator = Tabulator.from_keywords(\n... header,\n... columns=[0, 1],\n... group=['a', 'c'],\n... count='&lt;=20')\n&gt;&gt;&gt; # show the tab types tabulator will use\n&gt;&gt;&gt; print([type(tab).__name__ for tab in tabulator.tabs])\n['Membership', 'Comparison']\n&gt;&gt;&gt; # apply the tabulator to get the same rows\n&gt;&gt;&gt; rows = [tabulator(row) for row in data if tabulator(row)]\n&gt;&gt;&gt; print(rows)\n...\n[{'group': 'c', 'count': 2},\n{'group': 'c', 'count': 4},\n{'group': 'a', 'count': 19},\n{'group': 'c', 'count': 4},\n{'group': 'c', 'count': 5},\n{'group': 'a', 'count': 18},\n{'group': 'c', 'count': 1}]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Tabulator(ReprMixin):\n    \"\"\"A Callable for creating, storing &amp; applying Tabs to a row dictionary.\n\n    Tablulators are the interface that should be used to create Tab instances.\n    They allow Tabs to be constructed from keyword arguments and apply multiple\n    Tabs sequentially to a row dictionary of file data. If columns from the file\n    are provided, the Tabulator will restrict which columns of the row\n    dictionary will be returned.\n\n    Attributes:\n        header:\n            A Header instance storing all column names of a file.\n        tabs:\n            A list of tab instances to apply to each row.\n        columns:\n            Columns to extract from each row as a list of column names, a list\n            of integer column indices or a single re pattern to match column\n            names against.\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; names = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(names, values)) for values in items]\n        &gt;&gt;&gt; #create a Header instance\n        &gt;&gt;&gt; header = Header(line=0, names=names, string=''.join(names))\n        &gt;&gt;&gt; # create a tabulator from keyword args defining tabs\n        &gt;&gt;&gt; tabulator = Tabulator.from_keywords(\n        ... header,\n        ... columns=[0, 1],\n        ... group=['a', 'c'],\n        ... count='&lt;=20')\n        &gt;&gt;&gt; # show the tab types tabulator will use\n        &gt;&gt;&gt; print([type(tab).__name__ for tab in tabulator.tabs])\n        ['Membership', 'Comparison']\n        &gt;&gt;&gt; # apply the tabulator to get the same rows\n        &gt;&gt;&gt; rows = [tabulator(row) for row in data if tabulator(row)]\n        &gt;&gt;&gt; print(rows)\n        ... # doctest: +NORMALIZE_WHITESPACE\n        [{'group': 'c', 'count': 2},\n        {'group': 'c', 'count': 4},\n        {'group': 'a', 'count': 19},\n        {'group': 'c', 'count': 4},\n        {'group': 'c', 'count': 5},\n        {'group': 'a', 'count': 18},\n        {'group': 'c', 'count': 1}]\n    \"\"\"\n\n    def __init__(\n        self,\n        header: Header,\n        tabs: list[Tab] | None = None,\n        columns: list[str] | list[int] | re.Pattern | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize with tabs, columns to extract &amp; Header instance.\"\"\"\n\n        self.header = header\n        self.tabs = tabs if tabs else [Accepting()]\n        self.columns = self._assign(columns) if columns else self.header.names\n\n    def _assign(self, value: list[str] | list[int] | re.Pattern):\n        \"\"\"Assigns the passed column value(s) to valid column names.\n\n        Args:\n            value:\n                A list of column string names, a list of column indices, or\n                a single re pattern to match against names in header\n\n        Returns:\n            A list of column names.\n\n        Raises:\n            A ValueError is issued if value is not a list of strings, a list of\n            ints or an re Pattern.\n        \"\"\"\n\n        if isinstance(value, re.Pattern):\n            return [x for x in self.header.names if re.search(value, x)]\n\n        if all(isinstance(val, int) for val in value):\n            # cast for mypy to know value is list of ints\n            value = cast(list[int], value)\n            result = [self.header.names[val] for val in value]\n\n        elif all(isinstance(val, str) for val in value):\n            # cast for mypy to know value is list of strs\n            value = cast(list[str], value)\n            result = value\n\n        else:\n            msg = (\n                'Columns must be a sequence of ints, a sequence of strings, '\n                'or a compiled re pattern.'\n            )\n            raise ValueError(msg)\n\n        invalid = set(result).difference(self.header.names)\n        if any(invalid):\n            msg = f'Invalid name(s): {invalid} are being ignored.'\n            warnings.warn(msg)\n            result = [el for el in result if el not in invalid]\n\n        return result\n\n    # define a static method for a classmethod without instant access\n    # pylint: disable-next=no-self-argument\n    def _from_keyword(  # type: ignore [misc]\n        name: str,\n        value: (\n            str\n            | CellType\n            | Sequence[CellType]\n            | re.Pattern\n            | Callable[[dict[str, CellType], str], bool]\n        ),\n    ) -&gt; Tab:\n        \"\"\"Returns a Tab instance from the name, value kwarg pair.\n\n        This is a protected static method that aides the alternative\n        from_keywords constructor. It should not be externally called.\n\n        Args:\n            name:\n                The column name to provide to a Tab constructor.\n            value:\n                A value to provide to a Tab constructor.\n\n        Returns:\n            A Tab instance.\n        \"\"\"\n\n        rich_comparisons = '&lt; &gt; &lt;= &gt;= == !='.split()\n\n        if isinstance(value, str):\n            if any(compare in value for compare in rich_comparisons):\n                return Comparison(name, value)\n\n            return Equality(name, value)\n\n        if isinstance(value, CellType):\n            # non-string CellType value -&gt; make equality tab\n            return Equality(name, value)\n\n        if isinstance(value, Sequence):\n            return Membership(name, value)\n\n        if isinstance(value, re.Pattern):\n            return Regex(name, value)\n\n        if callable(value):\n            return Calling(name, value)\n\n        msg = f'Invalid value type {type(value)} in keyword argument'\n        raise TypeError(msg)\n\n    @classmethod\n    def from_keywords(\n        cls,\n        header: Header,\n        columns: list[str] | list[int] | re.Pattern | None = None,\n        **kwargs: (\n            CellType\n            | Sequence[CellType]\n            | re.Pattern\n            | Callable[[dict[str, CellType], str], bool]\n        ),\n    ) -&gt; Self:\n        \"\"\"Alternative instance constructor using keyword args to define Tabs.\n\n        Args:\n            header:\n                A Header type containing the names of all the columns in infile.\n            columns:\n                Columns to extract from each row as a list of column names, a list\n                of integer column indices or a single re pattern to match column\n                names against.\n            kwargs:\n                A mapping of column names and values to convert to Tab\n                instances (e.g. 'group' = ['a', 'b'], 'count' = '&lt;=20', ...)\n\n        Returns:\n            A Tabulator instance\n        \"\"\"\n\n        tabs = [cls._from_keyword(*item) for item in kwargs.items()]\n        return cls(header, tabs, columns)\n\n    def __call__(self, row: dict[str, CellType]) -&gt; dict[str, CellType] | None:\n        \"\"\"Apply Tab instances and column filter to this row.\n\n        Args:\n            row:\n                A row dictionary of a file whose values have been type casted.\n\n        Returns:\n            A row dictionary or None if row does not satisfy all tabs.\n        \"\"\"\n\n        if all(tab(row) for tab in self.tabs):\n            return {key: val for key, val in row.items() if key in self.columns}\n\n        return None\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Tabulator.__init__","title":"<code>__init__(header, tabs=None, columns=None)</code>","text":"<p>Initialize with tabs, columns to extract &amp; Header instance.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(\n    self,\n    header: Header,\n    tabs: list[Tab] | None = None,\n    columns: list[str] | list[int] | re.Pattern | None = None,\n) -&gt; None:\n    \"\"\"Initialize with tabs, columns to extract &amp; Header instance.\"\"\"\n\n    self.header = header\n    self.tabs = tabs if tabs else [Accepting()]\n    self.columns = self._assign(columns) if columns else self.header.names\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Tabulator.from_keywords","title":"<code>from_keywords(header, columns=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Alternative instance constructor using keyword args to define Tabs.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>Header</code> <p>A Header type containing the names of all the columns in infile.</p> required <code>columns</code> <code>list[str] | list[int] | Pattern | None</code> <p>Columns to extract from each row as a list of column names, a list of integer column indices or a single re pattern to match column names against.</p> <code>None</code> <code>kwargs</code> <code>CellType | Sequence[CellType] | Pattern | Callable[[dict[str, CellType], str], bool]</code> <p>A mapping of column names and values to convert to Tab instances (e.g. 'group' = ['a', 'b'], 'count' = '&lt;=20', ...)</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>A Tabulator instance</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>@classmethod\ndef from_keywords(\n    cls,\n    header: Header,\n    columns: list[str] | list[int] | re.Pattern | None = None,\n    **kwargs: (\n        CellType\n        | Sequence[CellType]\n        | re.Pattern\n        | Callable[[dict[str, CellType], str], bool]\n    ),\n) -&gt; Self:\n    \"\"\"Alternative instance constructor using keyword args to define Tabs.\n\n    Args:\n        header:\n            A Header type containing the names of all the columns in infile.\n        columns:\n            Columns to extract from each row as a list of column names, a list\n            of integer column indices or a single re pattern to match column\n            names against.\n        kwargs:\n            A mapping of column names and values to convert to Tab\n            instances (e.g. 'group' = ['a', 'b'], 'count' = '&lt;=20', ...)\n\n    Returns:\n        A Tabulator instance\n    \"\"\"\n\n    tabs = [cls._from_keyword(*item) for item in kwargs.items()]\n    return cls(header, tabs, columns)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Tabulator.__call__","title":"<code>__call__(row)</code>","text":"<p>Apply Tab instances and column filter to this row.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, CellType]</code> <p>A row dictionary of a file whose values have been type casted.</p> required <p>Returns:</p> Type Description <code>dict[str, CellType] | None</code> <p>A row dictionary or None if row does not satisfy all tabs.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; dict[str, CellType] | None:\n    \"\"\"Apply Tab instances and column filter to this row.\n\n    Args:\n        row:\n            A row dictionary of a file whose values have been type casted.\n\n    Returns:\n        A row dictionary or None if row does not satisfy all tabs.\n    \"\"\"\n\n    if all(tab(row) for tab in self.tabs):\n        return {key: val for key, val in row.items() if key in self.columns}\n\n    return None\n</code></pre>"},{"location":"reference/tabbing/#tabs","title":"TABS","text":""},{"location":"reference/tabbing/#tabbed.tabbing.Equality","title":"<code>tabbed.tabbing.Equality</code>","text":"<p>               Bases: <code>Tab</code></p> <p>A Tab to test if a value in a row dictionary equals another value.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The item name in row dictionary whose value will be compared.</p> <code>matching</code> <p>The value to compare against the named item in row dictionary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; header = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n&gt;&gt;&gt; # make an Equality tab\n&gt;&gt;&gt; tab = Equality('group', 'a')\n&gt;&gt;&gt; # call the tab on the rows and print rows that match\n&gt;&gt;&gt; results = [tab(row) for row in data]\n&gt;&gt;&gt; print([idx for idx, boolean in enumerate(results) if boolean])\n[0, 5, 9, 10]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Equality(Tab):\n    \"\"\"A Tab to test if a value in a row dictionary equals another value.\n\n    Attributes:\n        name:\n            The item name in row dictionary whose value will be compared.\n        matching:\n            The value to compare against the named item in row dictionary.\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; header = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n        &gt;&gt;&gt; # make an Equality tab\n        &gt;&gt;&gt; tab = Equality('group', 'a')\n        &gt;&gt;&gt; # call the tab on the rows and print rows that match\n        &gt;&gt;&gt; results = [tab(row) for row in data]\n        &gt;&gt;&gt; print([idx for idx, boolean in enumerate(results) if boolean])\n        [0, 5, 9, 10]\n    \"\"\"\n\n    def __init__(self, name: str, matching: CellType) -&gt; None:\n        \"\"\"Initialize this tab.\"\"\"\n\n        self.name = name\n        self.matching = matching\n\n    def __call__(self, row: dict[str, CellType]) -&gt; bool:\n        \"\"\"Apply this tab to a row dictionary.\n\n        Args:\n            row:\n                A row dictionary of a file whose values have been type casted.\n\n        Returns:\n            True if row's named value equals matching value and False otherwise.\n        \"\"\"\n\n        return bool(row[self.name] == self.matching)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Equality.__init__","title":"<code>__init__(name, matching)</code>","text":"<p>Initialize this tab.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(self, name: str, matching: CellType) -&gt; None:\n    \"\"\"Initialize this tab.\"\"\"\n\n    self.name = name\n    self.matching = matching\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Equality.__call__","title":"<code>__call__(row)</code>","text":"<p>Apply this tab to a row dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, CellType]</code> <p>A row dictionary of a file whose values have been type casted.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if row's named value equals matching value and False otherwise.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; bool:\n    \"\"\"Apply this tab to a row dictionary.\n\n    Args:\n        row:\n            A row dictionary of a file whose values have been type casted.\n\n    Returns:\n        True if row's named value equals matching value and False otherwise.\n    \"\"\"\n\n    return bool(row[self.name] == self.matching)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Membership","title":"<code>tabbed.tabbing.Membership</code>","text":"<p>               Bases: <code>Tab</code></p> <p>A Tab to test if a value in a row dictionary is a member of a collection.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The named value in row dict. to be member tested against collection.</p> <code>collection</code> <p>A sequence of items for testing membership.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; header = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n&gt;&gt;&gt; # make a membership tab\n&gt;&gt;&gt; members = Membership('color', ['r', 'b'])\n&gt;&gt;&gt; # call the tab on data and print matching rows\n&gt;&gt;&gt; results = [members(row) for row in data]\n&gt;&gt;&gt; print([idx for idx, boolean in enumerate(results) if boolean])\n[0, 2, 3, 4, 5, 6, 9, 10]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Membership(Tab):\n    \"\"\"A Tab to test if a value in a row dictionary is a member of a collection.\n\n    Attributes:\n        name:\n            The named value in row dict. to be member tested against collection.\n        collection:\n            A sequence of items for testing membership.\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; header = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n        &gt;&gt;&gt; # make a membership tab\n        &gt;&gt;&gt; members = Membership('color', ['r', 'b'])\n        &gt;&gt;&gt; # call the tab on data and print matching rows\n        &gt;&gt;&gt; results = [members(row) for row in data]\n        &gt;&gt;&gt; print([idx for idx, boolean in enumerate(results) if boolean])\n        [0, 2, 3, 4, 5, 6, 9, 10]\n    \"\"\"\n\n    def __init__(self, name: str, collection: Sequence[CellType]) -&gt; None:\n        \"\"\"Initialize this tab.\"\"\"\n\n        self.name = name\n        self.collection = set(collection)\n\n    def __call__(self, row: dict[str, CellType]) -&gt; bool:\n        \"\"\"Apply this tab to a row dictionary.\n\n        Args:\n            row:\n                A row dictionary of a file whose values have been type casted.\n\n        Returns:\n            True if named value in row is in collection.\n        \"\"\"\n\n        return row[self.name] in self.collection\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Membership.__init__","title":"<code>__init__(name, collection)</code>","text":"<p>Initialize this tab.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(self, name: str, collection: Sequence[CellType]) -&gt; None:\n    \"\"\"Initialize this tab.\"\"\"\n\n    self.name = name\n    self.collection = set(collection)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Membership.__call__","title":"<code>__call__(row)</code>","text":"<p>Apply this tab to a row dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, CellType]</code> <p>A row dictionary of a file whose values have been type casted.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if named value in row is in collection.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; bool:\n    \"\"\"Apply this tab to a row dictionary.\n\n    Args:\n        row:\n            A row dictionary of a file whose values have been type casted.\n\n    Returns:\n        True if named value in row is in collection.\n    \"\"\"\n\n    return row[self.name] in self.collection\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Regex","title":"<code>tabbed.tabbing.Regex</code>","text":"<p>               Bases: <code>Tab</code></p> <p>A Tab to test a compiled re pattern against a string value in a row dict.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The named value in row dictionary to be pattern tested.</p> <code>pattern</code> <p>A compiled regular expression pattern (see re.compile).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; header = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n&gt;&gt;&gt; # make a re pattern tab looking for a or c in group\n&gt;&gt;&gt; regex = Regex('group', re.compile(r'a|c'))\n&gt;&gt;&gt; #apply tab and find rows that match\n&gt;&gt;&gt; booleans = [regex(row) for row in data]\n&gt;&gt;&gt; print([idx for idx, boolean in enumerate(booleans) if boolean])\n[0, 1, 4, 5, 6, 8, 9, 10, 11]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Regex(Tab):\n    \"\"\"A Tab to test a compiled re pattern against a string value in a row dict.\n\n    Attributes:\n        name:\n            The named value in row dictionary to be pattern tested.\n        pattern:\n            A compiled regular expression pattern (see re.compile).\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; header = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n        &gt;&gt;&gt; # make a re pattern tab looking for a or c in group\n        &gt;&gt;&gt; regex = Regex('group', re.compile(r'a|c'))\n        &gt;&gt;&gt; #apply tab and find rows that match\n        &gt;&gt;&gt; booleans = [regex(row) for row in data]\n        &gt;&gt;&gt; print([idx for idx, boolean in enumerate(booleans) if boolean])\n        [0, 1, 4, 5, 6, 8, 9, 10, 11]\n    \"\"\"\n\n    def __init__(self, name: str, pattern: re.Pattern) -&gt; None:\n        \"\"\"Initialize this tab.\"\"\"\n\n        self.name = name\n        self.pattern = pattern\n\n    def __call__(self, row: dict[str, CellType]) -&gt; bool:\n        \"\"\"Apply this tab to a row dictionary.\n\n        Args:\n            row:\n                A row dictionary of a file whose values have been type casted.\n\n        Returns:\n            True if pattern is found in named value of row &amp; False otherwise.\n        \"\"\"\n\n        # row[self.name] may not be str type but let re throw error to avoid\n        # type checking every row of a file\n        return bool(\n            re.search(self.pattern, row[self.name])  # type: ignore [arg-type]\n        )\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Regex.__init__","title":"<code>__init__(name, pattern)</code>","text":"<p>Initialize this tab.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(self, name: str, pattern: re.Pattern) -&gt; None:\n    \"\"\"Initialize this tab.\"\"\"\n\n    self.name = name\n    self.pattern = pattern\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Regex.__call__","title":"<code>__call__(row)</code>","text":"<p>Apply this tab to a row dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, CellType]</code> <p>A row dictionary of a file whose values have been type casted.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if pattern is found in named value of row &amp; False otherwise.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; bool:\n    \"\"\"Apply this tab to a row dictionary.\n\n    Args:\n        row:\n            A row dictionary of a file whose values have been type casted.\n\n    Returns:\n        True if pattern is found in named value of row &amp; False otherwise.\n    \"\"\"\n\n    # row[self.name] may not be str type but let re throw error to avoid\n    # type checking every row of a file\n    return bool(\n        re.search(self.pattern, row[self.name])  # type: ignore [arg-type]\n    )\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Comparison","title":"<code>tabbed.tabbing.Comparison</code>","text":"<p>               Bases: <code>Tab</code></p> <p>A Tab to test if named value in a row dictionary satisfies a comparison.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The named value in row dictionary to compare.</p> <code>comparison</code> <p>A string containing one or two rich comparison operators followed by a Comparable type (e.g. '&gt;= 8.3', '&lt; 9 and &gt; 2'). The logical 'and' or 'or' may be used for double comparisons.</p> <code>permissive</code> <p>A boolean indicating whether comparisons between mismatched types should result in the row being accepted (True) or rejected (False). For example if row[name] = '-' and comparison requires row[name]</p> <p>3, permissive can accept or reject the row. The default value is True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; header = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n&gt;&gt;&gt; # make a comparison tab and apply it\n&gt;&gt;&gt; comparison = Comparison('count', '&gt;=4 and &lt; 18')\n&gt;&gt;&gt; booleans = [comparison(row) for row in data]\n&gt;&gt;&gt; print([idx for idx, boolean in enumerate(booleans) if boolean])\n[2, 3, 4, 6, 8]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Comparison(Tab):\n    \"\"\"A Tab to test if named value in a row dictionary satisfies a comparison.\n\n    Attributes:\n        name:\n            The named value in row dictionary to compare.\n        comparison:\n            A string containing one or two rich comparison operators followed by\n            a Comparable type (e.g. '&gt;= 8.3', '&lt; 9 and &gt; 2'). The logical 'and'\n            or 'or' may be used for double comparisons.\n        permissive:\n            A boolean indicating whether comparisons between mismatched types\n            should result in the row being accepted (True) or rejected (False).\n            For example if row[name] = '-' and comparison requires row[name]\n            &gt; 3, permissive can accept or reject the row. The default value is\n            True.\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; header = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n        &gt;&gt;&gt; # make a comparison tab and apply it\n        &gt;&gt;&gt; comparison = Comparison('count', '&gt;=4 and &lt; 18')\n        &gt;&gt;&gt; booleans = [comparison(row) for row in data]\n        &gt;&gt;&gt; print([idx for idx, boolean in enumerate(booleans) if boolean])\n        [2, 3, 4, 6, 8]\n    \"\"\"\n\n    comparators = {\n        '&lt;': op.lt,\n        '&gt;': op.gt,\n        '&lt;=': op.le,\n        '&gt;=': op.ge,\n        '==': op.eq,\n        '!=': op.ne,\n    }\n\n    logicals = {'and': op.__and__, 'or': op.__or__}\n\n    def __init__(\n        self,\n        name: str,\n        comparison: str,\n        permissive: bool = True,\n    ) -&gt; None:\n        \"\"\"Initialize this tab instance.\"\"\"\n\n        self.name = name\n        self.comparison = comparison\n        self.permissive = permissive\n        self._funcs, self._values, self._logical = self._parse()\n\n    def _singleparse(self, compare_str: str):\n        \"\"\"Parses a string containing a single comparison operator.\n\n        This protected method should not be called externally.\n\n        Args:\n            A string with one comparison operator followed by a Comparable type.\n\n        Returns:\n            An operator module function &amp; the casted comparing value.\n        \"\"\"\n\n        # -? =&gt; 0 or 1 occurrence of negative sign\n        # \\d* =&gt; 0 or more integer occurrences\n        # .? =&gt; 0 or 1 occurrence of a decimal\n        # \\d+ =&gt; greedily get remaining integers\n        match = re.search(r'-?\\d*\\.?\\d+', compare_str)\n        if not match:\n            msg = f'Could not parse {compare_str}'\n            raise ValueError(msg)\n        idx = match.span()[0]\n        name, value_str = compare_str[:idx], compare_str[idx:]\n        comparator = self.comparators[name.strip()]\n        value = parsing.convert(value_str, decimal='.')\n\n        return comparator, value\n\n    def _parse(self):\n        \"\"\"Parses a comparison string with one or two rich comparisons.\n\n        The steps to parsing a comparison string are; (1). splitting a comparison\n        string on any logicals, (2). extracting the comparator functions, and (3).\n        type casting the comparing value.\n\n        This protected method should not be called externally.\n\n        Returns:\n            A tuple of comparators, a tuple of comparing values, and a logical.\n            Logical will be None if comparison string contains a single\n            comparison.\n\n        Raises:\n            A ValueError is issued if comparison contains more than two rich\n            comparisons.\n        \"\"\"\n\n        logical = None\n        multicomparison = re.search(r'\\sand\\s|\\sor\\s', self.comparison)\n        if multicomparison:\n            # match cannot be None -- for mypy\n            logic_string = multicomparison.group()  # type: ignore [union-attr]\n            logical = self.logicals[logic_string.strip()]\n\n            # get each string comparisons and get func, value components\n            cstrings = re.split(logic_string, self.comparison)\n            if len(cstrings) &gt; 2:\n                raise ValueError('A maximum of two comparisons may be made')\n\n            items = [self._singleparse(compare_str) for compare_str in cstrings]\n            funcs, values = zip(*items)\n        else:\n            funcs, values = zip(*[self._singleparse(self.comparison)])\n\n        return funcs, values, logical\n\n    def __call__(self, row: dict[str, CellType]) -&gt; bool:\n        \"\"\"Apply this tab to a row dictionary.\n\n        Args:\n            row:\n                A row dictionary of a file whose values have been type casted.\n\n        Returns:\n            True if named value satisfies the comparison(s).\n\n        Raises:\n            ValueError: is issued if more than two logicals are in comparison.\n        \"\"\"\n\n        try:\n\n            booleans = []\n            for func, val in zip(self._funcs, self._values):\n                booleans.append(func(row[self.name], val))\n\n            if self._logical:\n                # combine multicomparison with logical\n                return bool(self._logical(*booleans))\n\n            return bool(booleans[0])\n\n        except TypeError:\n            # comparisons between incompatible types -&gt; return permissive\n            return self.permissive\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Comparison.__init__","title":"<code>__init__(name, comparison, permissive=True)</code>","text":"<p>Initialize this tab instance.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    comparison: str,\n    permissive: bool = True,\n) -&gt; None:\n    \"\"\"Initialize this tab instance.\"\"\"\n\n    self.name = name\n    self.comparison = comparison\n    self.permissive = permissive\n    self._funcs, self._values, self._logical = self._parse()\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Comparison.__call__","title":"<code>__call__(row)</code>","text":"<p>Apply this tab to a row dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, CellType]</code> <p>A row dictionary of a file whose values have been type casted.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if named value satisfies the comparison(s).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>is issued if more than two logicals are in comparison.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; bool:\n    \"\"\"Apply this tab to a row dictionary.\n\n    Args:\n        row:\n            A row dictionary of a file whose values have been type casted.\n\n    Returns:\n        True if named value satisfies the comparison(s).\n\n    Raises:\n        ValueError: is issued if more than two logicals are in comparison.\n    \"\"\"\n\n    try:\n\n        booleans = []\n        for func, val in zip(self._funcs, self._values):\n            booleans.append(func(row[self.name], val))\n\n        if self._logical:\n            # combine multicomparison with logical\n            return bool(self._logical(*booleans))\n\n        return bool(booleans[0])\n\n    except TypeError:\n        # comparisons between incompatible types -&gt; return permissive\n        return self.permissive\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Calling","title":"<code>tabbed.tabbing.Calling</code>","text":"<p>               Bases: <code>Tab</code></p> <p>A Tab to test if named value in a row satisfies a boolean function.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the row dictionary item to supply to func.</p> <code>func</code> <p>A boolean returning callable that accepts a row, a name and any required kwargs in that order.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; header = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n&gt;&gt;&gt; # make a callable that determines if values are even\n&gt;&gt;&gt; def is_even(row, name):\n...     return row[name] % 2 == 0\n&gt;&gt;&gt; calling = Calling('count', is_even)\n&gt;&gt;&gt; # apply the tab and print rows that are even\n&gt;&gt;&gt; booleans = [calling(row) for row in data]\n&gt;&gt;&gt; print([idx for idx, boolean in enumerate(booleans) if boolean])\n[0, 1, 4, 6, 9, 10]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Calling(Tab):\n    \"\"\"A Tab to test if named value in a row satisfies a boolean function.\n\n    Attributes:\n        name:\n            The name of the row dictionary item to supply to func.\n        func:\n            A boolean returning callable that accepts a row, a name and any\n            required kwargs in that order.\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; header = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n        &gt;&gt;&gt; # make a callable that determines if values are even\n        &gt;&gt;&gt; def is_even(row, name):\n        ...     return row[name] % 2 == 0\n        &gt;&gt;&gt; calling = Calling('count', is_even)\n        &gt;&gt;&gt; # apply the tab and print rows that are even\n        &gt;&gt;&gt; booleans = [calling(row) for row in data]\n        &gt;&gt;&gt; print([idx for idx, boolean in enumerate(booleans) if boolean])\n        [0, 1, 4, 6, 9, 10]\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        func: Callable[[dict[str, CellType], str], bool],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Initialize this tab instance.\"\"\"\n\n        self.name = name\n        self.func = func\n        self.kwargs = kwargs\n\n    def __call__(self, row: dict[str, CellType]) -&gt; bool:\n        \"\"\"Apply this tab to a row dictionary.\n\n        Args:\n            row:\n                A row dictionary of a file whose values have been type casted.\n\n        Returns:\n            True if func returns True for this row and False otherwise.\n        \"\"\"\n\n        return self.func(row, self.name, **self.kwargs)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Calling.__init__","title":"<code>__init__(name, func, **kwargs)</code>","text":"<p>Initialize this tab instance.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    func: Callable[[dict[str, CellType], str], bool],\n    **kwargs,\n) -&gt; None:\n    \"\"\"Initialize this tab instance.\"\"\"\n\n    self.name = name\n    self.func = func\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Calling.__call__","title":"<code>__call__(row)</code>","text":"<p>Apply this tab to a row dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>dict[str, CellType]</code> <p>A row dictionary of a file whose values have been type casted.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if func returns True for this row and False otherwise.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; bool:\n    \"\"\"Apply this tab to a row dictionary.\n\n    Args:\n        row:\n            A row dictionary of a file whose values have been type casted.\n\n    Returns:\n        True if func returns True for this row and False otherwise.\n    \"\"\"\n\n    return self.func(row, self.name, **self.kwargs)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Accepting","title":"<code>tabbed.tabbing.Accepting</code>","text":"<p>               Bases: <code>Tab</code></p> <p>A Tab that returns True for any row dictionary.</p> <p>This Tab defines what to do with a row when no tabs are present.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # make tabular data\n&gt;&gt;&gt; header = ['group', 'count', 'color']\n&gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n&gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n&gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n&gt;&gt;&gt; items = zip(group, count, color)\n&gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n&gt;&gt;&gt; # make Accepting tab\n&gt;&gt;&gt; accepting = Accepting(x='twiddle', y='dee')\n&gt;&gt;&gt; # apply the accepting tab to data\n&gt;&gt;&gt; booleans = [accepting(row) for row in data]\n&gt;&gt;&gt; print([idx for idx, val in enumerate(booleans) if val])\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n</code></pre> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>class Accepting(Tab):\n    \"\"\"A Tab that returns True for any row dictionary.\n\n    This Tab defines what to do with a row when no tabs are present.\n\n    Examples:\n        &gt;&gt;&gt; # make tabular data\n        &gt;&gt;&gt; header = ['group', 'count', 'color']\n        &gt;&gt;&gt; group = ['a', 'c', 'b', 'b', 'c', 'a', 'c', 'b', 'c', 'a', 'a', 'c']\n        &gt;&gt;&gt; count = [22,   2,   13,  15,  4,   19,  4,   21,  5,   24,  18,  1]\n        &gt;&gt;&gt; color = 'r g b b r r r g g  b b g'.split()\n        &gt;&gt;&gt; items = zip(group, count, color)\n        &gt;&gt;&gt; data = [dict(zip(header, values)) for values in items]\n        &gt;&gt;&gt; # make Accepting tab\n        &gt;&gt;&gt; accepting = Accepting(x='twiddle', y='dee')\n        &gt;&gt;&gt; # apply the accepting tab to data\n        &gt;&gt;&gt; booleans = [accepting(row) for row in data]\n        &gt;&gt;&gt; print([idx for idx, val in enumerate(booleans) if val])\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize this Tab.\"\"\"\n\n        self.__dict__.update(kwargs)\n\n    def __call__(self, row: dict[str, CellType]) -&gt; Literal[True]:\n        \"\"\"Returns True for a row dictionary always.\"\"\"\n\n        return True\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Accepting.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize this Tab.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize this Tab.\"\"\"\n\n    self.__dict__.update(kwargs)\n</code></pre>"},{"location":"reference/tabbing/#tabbed.tabbing.Accepting.__call__","title":"<code>__call__(row)</code>","text":"<p>Returns True for a row dictionary always.</p> Source code in <code>src/tabbed/tabbing.py</code> <pre><code>def __call__(self, row: dict[str, CellType]) -&gt; Literal[True]:\n    \"\"\"Returns True for a row dictionary always.\"\"\"\n\n    return True\n</code></pre>"}]}